"""
ç«¶é¦¬äºˆæƒ³AI - scraper_v7.pyï¼ˆScraplingå¯¾å¿œç‰ˆï¼‰
æœ€çµ‚æ›´æ–°: 2026å¹´2æœˆ24æ—¥

ä¸»ãªå¤‰æ›´ç‚¹ (v6â†’v7):
- ã€æœ€é‡è¦ã€‘requests + BeautifulSoup â†’ Scrapling ã® Fetcher ã«å®Œå…¨ç§»è¡Œ
  - EUC-JPã®è‡ªå‹•ãƒ‡ã‚³ãƒ¼ãƒ‰å¯¾å¿œï¼ˆresponse.encoding = 'EUC-JP' ä¸è¦ï¼‰
  - Cloudflareç­‰ã®botæ¤œçŸ¥ã‚’å›é¿ï¼ˆcurl_cffiãƒ™ãƒ¼ã‚¹ã®TLSå½è£…ï¼‰
  - ã‚»ãƒ¬ã‚¯ã‚¿APIãŒç°¡æ½”ï¼ˆcss/xpath/find/find_all â†’ Scraplingãƒã‚¤ãƒ†ã‚£ãƒ–ï¼‰
- adaptive=True ã§ã‚»ãƒ¬ã‚¯ã‚¿å¤‰æ›´ã¸ã®è‡ªå‹•é©å¿œï¼ˆã‚µã‚¤ãƒˆæ”¹ä¿®ã¸ã®è€æ€§ï¼‰
- _get_race_last_3f_stats / _parse_shutuba / _get_horse_history ã‚’Scraplingã«æ›¸ãæ›ãˆ
- requests.Sessionã‚’å»ƒæ­¢ â†’ Fetcher.get() ã«çµ±ä¸€ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¯å†…éƒ¨ã§è‡ªå‹•ï¼‰
- v6ã®å…¨æ©Ÿèƒ½ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€è„šè³ªåˆ†æã€ãƒšãƒ¼ã‚¹äºˆæ¸¬ã€ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼‰ã‚’å®Œå…¨ç¶™æ‰¿

å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
  pip install scrapling[all]
  scrapling-install  # Playwrightç­‰ã®ãƒ–ãƒ©ã‚¦ã‚¶ãƒ‰ãƒ©ã‚¤ãƒï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
"""

import time
import re
import logging
import statistics
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from collections import Counter

import pandas as pd

# â”€â”€ Scrapling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from scrapling import Fetcher          # é™çš„ãƒšãƒ¼ã‚¸ç”¨ï¼ˆcurl_cffi / TLSå½è£…ï¼‰
# from scrapling import StealthyFetcher  # ã‚ˆã‚Šå¼·åŠ›ãªbotå›é¿ãŒå¿…è¦ãªå ´åˆ
# from scrapling import PlayWrightFetcher  # JSæç”»ãŒå¿…è¦ãªå ´åˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from enhanced_scorer_v7 import RaceScorer
except ImportError as e:
    logger.error(f"Import error: {e}")
    raise ImportError("enhanced_scorer_v7.py ãŒå¿…è¦ã§ã™")


class NetkeibaRaceScraper:
    """netkeibaã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v7ï¼ˆScraplingå¯¾å¿œç‰ˆï¼‰"""

    def __init__(self, scraping_delay: float = 1.5, debug_mode: bool = False):
        # â”€â”€ Scraplingã®ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # adaptive=True: éå»ã®æˆåŠŸã‚»ãƒ¬ã‚¯ã‚¿ã‚’è¨˜æ†¶ã—ã€ã‚µã‚¤ãƒˆæ”¹ä¿®å¾Œã‚‚è‡ªå‹•é©å¿œ
        # stealthy=False â†’ Fetcher ã§ååˆ†ã€‚botæ¤œçŸ¥ãŒå³ã—ã„å ´åˆã¯ StealthyFetcher ã¸
        self.fetcher = Fetcher(auto_match=True)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        self.scorer = RaceScorer(debug_mode=debug_mode)
        self.scraping_delay = scraping_delay
        self.debug_mode = debug_mode
        self.debug_logs: List[str] = []
        self.skip_new_horse = True
        self.cache_hits = 0
        self.api_calls = 0
        self.race_stats_cache: Dict[str, Dict] = {}
        self.progress_callback = None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # å†…éƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆv6ã‹ã‚‰ç¶™æ‰¿ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _debug_print(self, message: str, level: str = "INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        if self.debug_mode:
            print(log_entry)
        self.debug_logs.append(log_entry)
        if level == "ERROR":
            logger.error(message)
        elif level == "WARNING":
            logger.warning(message)
        else:
            logger.info(message)

    def _parse_sex_age(self, sex_age_str: str) -> Tuple[Optional[int], Optional[str]]:
        if not sex_age_str:
            return None, None
        import unicodedata
        normalized = unicodedata.normalize('NFKC', sex_age_str).replace(' ', '').replace('\u3000', '')
        match = re.match(r'^([ç‰¡ç‰ã‚»])(\d{1,2})$', normalized)
        if match:
            return int(match.group(2)), match.group(1)
        return None, None

    def _get_course_name(self, race_id: str) -> str:
        venues = {
            "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ",
            "05": "æ±äº¬", "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½",
            "09": "é˜ªç¥", "10": "å°å€‰"
        }
        code = race_id[4:6] if len(race_id) >= 6 else ""
        return venues.get(code, "ä¸æ˜")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆv6ã‹ã‚‰ç¶™æ‰¿ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _init_session_state(self) -> bool:
        try:
            import streamlit as st
            if 'horse_cache_by_name' not in st.session_state:
                st.session_state.horse_cache_by_name = {}
            if 'race_cache' not in st.session_state:
                st.session_state.race_cache = {}
            return True
        except ImportError:
            return False

    def _get_cache_key_by_name(self, horse_name: str) -> str:
        return re.sub(r'\s+', '', horse_name).lower()

    def _get_from_cache(self, horse_name: str) -> Optional[List[Dict]]:
        if not self._init_session_state():
            return None
        try:
            import streamlit as st
            cache_key = self._get_cache_key_by_name(horse_name)
            if cache_key in st.session_state.horse_cache_by_name:
                self.cache_hits += 1
                self._debug_print(f"  ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ(é¦¬å): {horse_name}", "DEBUG")
                return st.session_state.horse_cache_by_name[cache_key]
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    def _save_to_cache(self, horse_name: str, data: List[Dict]):
        if not self._init_session_state():
            return
        try:
            import streamlit as st
            st.session_state.horse_cache_by_name[self._get_cache_key_by_name(horse_name)] = data
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _check_race_cache(self, race_name: str, horse_names: List[str]) -> Optional[pd.DataFrame]:
        if not self._init_session_state():
            return None
        try:
            import streamlit as st
            race_key = re.sub(r'\s+', '', race_name).lower()
            horse_set = set(self._get_cache_key_by_name(h) for h in horse_names)
            for cached_race, cached_df in st.session_state.race_cache.items():
                if cached_race == race_key:
                    cached_horses = set(self._get_cache_key_by_name(h) for h in cached_df['é¦¬å'].tolist())
                    if horse_set == cached_horses:
                        self._debug_print(f"ğŸ“¦ ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {race_name}", "INFO")
                        return cached_df
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    def _save_race_cache(self, race_name: str, df: pd.DataFrame):
        if not self._init_session_state():
            return
        try:
            import streamlit as st
            race_key = re.sub(r'\s+', '', race_name).lower()
            st.session_state.race_cache[race_key] = df.copy()
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def get_cache_stats(self) -> Dict:
        try:
            import streamlit as st
            name_cache_size = len(st.session_state.get('horse_cache_by_name', {}))
            race_cache_size = len(st.session_state.get('race_cache', {}))
        except Exception:
            name_cache_size = race_cache_size = 0
        total = self.cache_hits + self.api_calls
        return {
            'name_cache_size': name_cache_size,
            'race_cache_size': race_cache_size,
            'cache_hits': self.cache_hits,
            'api_calls': self.api_calls,
            'hit_rate': (self.cache_hits / total * 100) if total > 0 else 0,
        }

    def clear_cache(self):
        try:
            import streamlit as st
            st.session_state.horse_cache_by_name = {}
            st.session_state.race_cache = {}
        except Exception:
            pass
        self.cache_hits = 0
        self.api_calls = 0
        self.race_stats_cache = {}
        logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # è„šè³ªãƒ»ãƒšãƒ¼ã‚¹åˆ†æï¼ˆv6ã‹ã‚‰ç¶™æ‰¿ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _extract_running_style_from_history(self, history: List[Dict]) -> Optional[Dict]:
        if not history:
            return None
        styles = []
        for race in history[:5]:
            corner_pos = race.get('corner_pos', 0) or race.get('position_4c', 0)
            field_size = race.get('field_size', 16)
            last_3f = race.get('last_3f', 0.0)
            race_avg_3f = race.get('race_avg_last_3f', 0.0)
            if corner_pos > 0 and field_size > 0:
                style_info = self.scorer.style_analyzer.classify_running_style(
                    position_4c=corner_pos, field_size=field_size,
                    last_3f=last_3f, race_avg_3f=race_avg_3f
                )
                if style_info and style_info.get('style') != 'ä¸æ˜':
                    styles.append(style_info)
        if not styles:
            return None
        style_counts = Counter(s['style'] for s in styles)
        most_common_style = style_counts.most_common(1)[0][0]
        matching_styles = [s for s in styles if s['style'] == most_common_style]
        avg_confidence = sum(s['confidence'] for s in matching_styles) / len(matching_styles)
        consistency = len(matching_styles) / len(styles)
        return {
            'style': most_common_style,
            'confidence': min(avg_confidence * (0.7 + 0.3 * consistency), 0.95)
        }

    def _predict_race_pace(self, horses_running_styles: List[Dict],
                           field_size: int, course: str = 'æ±äº¬') -> Dict:
        if not horses_running_styles:
            return {'pace': 'ãƒŸãƒ‰ãƒ«', 'front_ratio': 0.30}
        pace_result = self.scorer.style_analyzer.predict_race_pace(
            horses_running_styles, field_size, course
        )
        style_counts = Counter(
            h.get('style', 'ä¸æ˜') for h in horses_running_styles
            if h.get('style') != 'ä¸æ˜'
        )
        pace_result['distribution'] = {
            'é€ƒã’': style_counts.get('é€ƒã’', 0),
            'å…ˆè¡Œ': style_counts.get('å…ˆè¡Œ', 0),
            'å·®ã—': style_counts.get('å·®ã—', 0),
            'è¿½è¾¼': style_counts.get('è¿½è¾¼', 0),
        }
        return pace_result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â–¼â–¼â–¼ Scraplingæ›¸ãæ›ãˆï¼šãƒ¬ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ï¼ˆå‡ºé¦¬è¡¨ï¼‰å–å¾— â–¼â–¼â–¼
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _fetch_page(self, url: str, encoding: str = 'EUC-JP'):
        """
        Scraplingã§ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦ Adaptor ã‚’è¿”ã™ã€‚
        - curl_cffiãƒ™ãƒ¼ã‚¹ã®TLSå½è£…ã§botæ¤œçŸ¥ã‚’å›é¿
        - encoding ã‚’æ˜ç¤ºæŒ‡å®šï¼ˆnetkeiba ã¯ EUC-JPï¼‰
        """
        response = self.fetcher.get(url, timeout=15, encoding=encoding)
        return response  # Scrapling ã® Response/Adaptor ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    def _get_race_info(self, page) -> Tuple[str, int, str, str]:
        """ãƒ¬ãƒ¼ã‚¹åãƒ»è·é›¢ãƒ»é¦¬å ´ãƒ»ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ã‚’å–å¾—ï¼ˆScraplingã‚»ãƒ¬ã‚¯ã‚¿ç‰ˆï¼‰"""
        # ãƒ¬ãƒ¼ã‚¹å
        race_name_elem = page.css_first('.RaceName')
        if race_name_elem:
            race_name = re.sub(r"å‡ºé¦¬è¡¨.*", "", race_name_elem.text).strip()
        else:
            h1 = page.css_first('h1')
            race_name = re.sub(r"å‡ºé¦¬è¡¨.*", "", h1.text).strip() if h1 else "ãƒ¬ãƒ¼ã‚¹"

        # è·é›¢ãƒ»ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ãƒ»é¦¬å ´
        race_data_elem = page.css_first('.RaceData01')
        race_distance = 1600
        track_type = "ä¸æ˜"
        baba = "è‰¯"

        if race_data_elem:
            text = race_data_elem.text
            dist_match = re.search(r"[èŠãƒ€éšœ](\d+)m", text)
            if dist_match:
                race_distance = int(dist_match.group(1))

            # ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ï¼ˆéšœå®³ã‚’æœ€å„ªå…ˆï¼‰
            if "éšœ" in text:
                track_type = "éšœå®³"
            elif "èŠ" in text:
                track_type = "èŠ"
            elif "ãƒ€" in text:
                track_type = "ãƒ€ãƒ¼ãƒˆ"

            # é¦¬å ´çŠ¶æ…‹
            if "ä¸è‰¯" in text:
                baba = "ä¸è‰¯"
            elif "ç¨é‡" in text or "ç¨" in text:
                baba = "ç¨é‡"
            elif "é‡" in text and "ç¨" not in text:
                baba = "é‡"
            else:
                baba = "è‰¯"

        # ãƒ¬ãƒ¼ã‚¹åã«ã€Œéšœå®³ã€ãŒã‚ã‚Œã°ä¸Šæ›¸ã
        if "éšœå®³" in race_name or "éšœ" in race_name:
            track_type = "éšœå®³"

        return race_name, race_distance, track_type, baba

    def _parse_shutuba(self, page) -> List[Dict]:
        """
        å‡ºé¦¬è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’Scraplingã§è§£æã€‚
        v6ã®è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã‚’ css() ã§ç°¡æ½”åŒ–ã€‚
        """
        horse_data = []

        # å‡ºé¦¬è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        table = (
            page.css_first('table.Shutuba_Table') or
            page.css_first('table[class*="shutuba" i]') or
            page.css_first('table.RaceList')
        )
        if not table:
            # ã€Œé¦¬åã€ã‚’å«ã‚€ä»»æ„ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            for t in page.css('table'):
                if t.css_first('th') and ('é¦¬å' in t.html_content or 'horse' in t.html_content.lower()):
                    table = t
                    break

        if not table:
            self._debug_print("âŒ å‡ºé¦¬è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return []

        rows = table.css('tr')
        start = 1 if rows and rows[0].css('th') else 0

        for row_idx, row in enumerate(rows[start:], 1):
            cols = row.css('td, th')
            if len(cols) < 5:
                continue
            try:
                info = self._extract_horse_info_scrapling(cols, row_idx)
                if info and info.get("é¦¬å") and info.get("horse_id"):
                    horse_data.append(info)
            except Exception as e:
                if self.debug_mode:
                    self._debug_print(f"  è¡Œ{row_idx}ã®è§£æå¤±æ•—: {e}", "WARNING")

        return horse_data

    def _extract_horse_info_scrapling(self, cols, row_idx: int) -> Optional[Dict]:
        """
        Scraplingã® Adaptor API ã§é¦¬æƒ…å ±ã‚’æŠ½å‡ºã€‚
        v6ã® BeautifulSoup ç‰ˆã‚ˆã‚Šç°¡æ½”ã€‚
        """
        import unicodedata

        info = {
            "æ ": "", "é¦¬ç•ª": "", "é¦¬å": "", "æ€§é½¢": "",
            "æ–¤é‡": 54.0, "é¨æ‰‹": "", "ã‚ªãƒƒã‚º": 1.0, "horse_id": ""
        }

        # é¦¬åãƒ»horse_id: /horse/NNNN... ã®ãƒªãƒ³ã‚¯
        for col in cols:
            horse_link = col.css_first('a[href*="/horse/"]')
            if horse_link and not info["é¦¬å"]:
                info["é¦¬å"] = horse_link.text.strip()
                match = re.search(r"/horse/(\d{10,})", horse_link.attrib.get('href', ''))
                if match:
                    info["horse_id"] = match.group(1)

        # é¨æ‰‹: /jockey/ ã®ãƒªãƒ³ã‚¯
        for col in cols:
            jockey_link = col.css_first('a[href*="/jockey/"]')
            if jockey_link and not info["é¨æ‰‹"]:
                info["é¨æ‰‹"] = jockey_link.text.strip()

        # æ ãƒ»é¦¬ç•ªï¼ˆå…ˆé ­3åˆ—ï¼‰
        for idx in range(min(3, len(cols))):
            text = cols[idx].text.strip()
            if not info["æ "] and len(text) == 1 and text.isdigit() and 1 <= int(text) <= 8:
                info["æ "] = text
            elif not info["é¦¬ç•ª"] and len(text) <= 2 and text.isdigit() and 1 <= int(text) <= 18:
                info["é¦¬ç•ª"] = text

        # æ€§é½¢ãƒ»æ–¤é‡
        for col in cols:
            text = col.text.strip()
            norm = unicodedata.normalize('NFKC', text).replace(' ', '').replace('\u3000', '')

            if not info["æ€§é½¢"]:
                if re.match(r"^[ç‰¡ç‰ã‚»]\d{1,2}$", norm):
                    info["æ€§é½¢"] = norm
                else:
                    m = re.search(r'([ç‰¡ç‰ã‚»])(\d{1,2})', norm)
                    if m:
                        info["æ€§é½¢"] = m.group(1) + m.group(2)
                # ã‚µãƒ–è¦ç´ ï¼ˆspan/divï¼‰ã‚‚æ¢ç´¢
                if not info["æ€§é½¢"]:
                    for sub in col.css('span, div'):
                        sub_norm = unicodedata.normalize('NFKC', sub.text.strip()).replace(' ', '')
                        if re.match(r"^[ç‰¡ç‰ã‚»]\d{1,2}$", sub_norm):
                            info["æ€§é½¢"] = sub_norm
                            break

            if info["æ–¤é‡"] == 54.0:
                wm = re.match(r"^(\d{2}(?:\.\d)?)$", text)
                if wm:
                    val = float(wm.group(1))
                    if 48.0 <= val <= 60.0:
                        info["æ–¤é‡"] = val

        if not info["é¦¬å"] or not info["horse_id"]:
            return None
        if not info["æ "]:
            info["æ "] = str(row_idx)
        if not info["é¦¬ç•ª"]:
            info["é¦¬ç•ª"] = str(row_idx)

        return info

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â–¼â–¼â–¼ Scraplingæ›¸ãæ›ãˆï¼šé¦¬ã®éå»æˆ¦ç¸¾å–å¾— â–¼â–¼â–¼
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _get_horse_history(self, horse_id: str, current_weight: float,
                           target_distance: int, target_course: str) -> List[Dict]:
        """
        æˆ¦ç¸¾ãƒšãƒ¼ã‚¸ã‚’Scraplingã§å–å¾—ãƒ»è§£æã€‚
        v6ã‹ã‚‰å¤‰æ›´ç‚¹:
        - requests â†’ Fetcher.get()
        - BeautifulSoup â†’ Scraplingã®css()/find()
        - EUC-JPã¯ encoding='EUC-JP' ã§è‡ªå‹•å‡¦ç†
        """
        url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
        try:
            page = self._fetch_page(url, encoding='EUC-JP')
        except Exception as e:
            logger.error(f"æˆ¦ç¸¾å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

        # æˆ¦ç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«
        table = page.css_first('table.db_h_race_results')
        if not table:
            return []

        headers = [th.text.strip() for th in table.css('th')]

        def find_col(keywords):
            for kw in keywords:
                for i, h in enumerate(headers):
                    if kw in h:
                        return i
            return -1

        idx_date     = find_col(["æ—¥ä»˜"])
        idx_course   = find_col(["é–‹å‚¬"])
        idx_race     = find_col(["ãƒ¬ãƒ¼ã‚¹å"])
        idx_dist     = find_col(["è·é›¢"])
        idx_chakujun = find_col(["ç€é †"])
        idx_weight   = find_col(["æ–¤é‡"])
        idx_chakusa  = find_col(["ç€å·®"])
        idx_3f       = find_col(["ä¸Šã‚Š"])
        idx_time     = find_col(["ã‚¿ã‚¤ãƒ ", "èµ°ç ´ã‚¿ã‚¤ãƒ "])
        idx_corner   = find_col(["é€šéé †ä½", "é€šé", "ã‚³ãƒ¼ãƒŠãƒ¼"])
        idx_tosu     = find_col(["é ­æ•°", "å‡ºèµ°é ­æ•°"])

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆï¼‰
        if idx_date     == -1: idx_date     = 0
        if idx_course   == -1: idx_course   = 1
        if idx_race     == -1: idx_race     = 4
        if idx_dist     == -1: idx_dist     = 14
        if idx_chakujun == -1: idx_chakujun = 11
        if idx_weight   == -1: idx_weight   = 13
        if idx_chakusa  == -1: idx_chakusa  = 18
        if idx_3f       == -1: idx_3f       = 20

        rows = table.css('tr')[1:8]  # æœ€å¤§7è¡Œï¼ˆä¸­æ­¢ãƒ»é™¤å¤–ã‚¹ã‚­ãƒƒãƒ—ã§5èµ°åˆ†ç¢ºä¿ï¼‰
        history = []

        _known_courses = [
            "æœ­å¹Œ", "å‡½é¤¨", "ç¦å³¶", "æ–°æ½Ÿ", "æ±äº¬", "ä¸­å±±", "ä¸­äº¬", "äº¬éƒ½", "é˜ªç¥", "å°å€‰",
            "å¤§äº•", "å·å´", "èˆ¹æ©‹", "æµ¦å’Œ", "é–€åˆ¥", "ç››å²¡", "æ°´æ²¢", "é‡‘æ²¢", "ç¬ æ¾",
            "åå¤å±‹", "åœ’ç”°", "å§«è·¯", "é«˜çŸ¥", "ä½è³€"
        ]

        for idx, row in enumerate(rows):
            cols = row.css('td')
            if len(cols) <= max(idx_date, idx_course, idx_race, idx_dist,
                                idx_chakujun, idx_weight, idx_chakusa):
                continue
            try:
                # â”€â”€ æ—¥ä»˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                date_raw = cols[idx_date].text.strip()
                dm = re.search(r'(\d{4})[å¹´/](\d{1,2})[æœˆ/](\d{1,2})', date_raw)
                date = f"{dm.group(1)}/{int(dm.group(2)):02d}/{int(dm.group(3)):02d}" if dm else date_raw

                # â”€â”€ ã‚³ãƒ¼ã‚¹ï¼ˆç«¶é¦¬å ´åï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                course_raw = cols[idx_course].text.strip()
                course_name = next((c for c in _known_courses if c in course_raw), course_raw)

                # â”€â”€ ãƒ¬ãƒ¼ã‚¹åãƒ»race_id â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                race_cell = cols[idx_race]
                race_link = race_cell.css_first('a')
                race_name_hist = race_link.text.strip() if race_link else race_cell.text.strip()
                race_id = ""
                if race_link:
                    href = race_link.attrib.get('href', '')
                    m = re.search(r"race/(\d{12})", href)
                    if m:
                        race_id = m.group(1)

                # â”€â”€ è·é›¢ãƒ»ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                dist_text = cols[idx_dist].text.strip()
                track_type_match = re.match(r"^(èŠ|ãƒ€|ãƒ€ãƒ¼ãƒˆ|éšœ)", dist_text)
                if track_type_match:
                    tp = track_type_match.group(1)
                    race_track_type = "èŠ" if tp == "èŠ" else "ãƒ€ãƒ¼ãƒˆ" if tp in ["ãƒ€", "ãƒ€ãƒ¼ãƒˆ"] else "éšœå®³"
                else:
                    race_track_type = "ä¸æ˜"
                dist_m = re.search(r"(\d+)", dist_text)
                distance = int(dist_m.group(1)) if dist_m else 0

                # â”€â”€ ç€é †ï¼ˆä¸­æ­¢ãƒ»é™¤å¤–ãƒ»å–æ¶ˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                chakujun_text = cols[idx_chakujun].text.strip()
                if any(kw in chakujun_text for kw in ["ä¸­æ­¢", "é™¤å¤–", "å–æ¶ˆ", "å–ã‚Šæ¶ˆ"]):
                    continue
                cm = re.search(r"(\d+)", chakujun_text)
                chakujun = int(cm.group(1)) if cm else 99

                # â”€â”€ ç€å·® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                chakusa_text = cols[idx_chakusa].text.strip() if idx_chakusa < len(cols) else ""
                winner_margin = 0.0
                if chakujun == 1:
                    goal_time_diff = 0.0
                    try:
                        winner_margin = float(chakusa_text)
                    except Exception:
                        winner_margin = 0.0
                else:
                    try:
                        goal_time_diff = float(chakusa_text)
                    except Exception:
                        goal_time_diff = 0.0

                # â”€â”€ æ–¤é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                try:
                    weight = float(cols[idx_weight].text.strip())
                except Exception:
                    weight = current_weight

                # â”€â”€ ä¸ŠãŒã‚Š3F â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                try:
                    last_3f = float(cols[idx_3f].text.strip()) if idx_3f < len(cols) else 0.0
                except Exception:
                    last_3f = 0.0

                # â”€â”€ èµ°ç ´ã‚¿ã‚¤ãƒ  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                goal_sec = 0.0
                if idx_time != -1 and idx_time < len(cols):
                    time_raw = cols[idx_time].text.strip()
                    try:
                        if ':' in time_raw:
                            parts = time_raw.split(':')
                            goal_sec = int(parts[0]) * 60 + float(parts[1])
                        else:
                            goal_sec = float(time_raw)
                    except Exception:
                        pass

                # â”€â”€ é€šéé †ä½ï¼ˆ4è§’ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                corner_pos = 0
                if idx_corner != -1 and idx_corner < len(cols):
                    positions = re.findall(r'\d+', cols[idx_corner].text.strip())
                    if positions:
                        corner_pos = int(positions[-1])

                # â”€â”€ å‡ºèµ°é ­æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                field_size = 16
                if idx_tosu != -1 and idx_tosu < len(cols):
                    tm = re.search(r'(\d+)', cols[idx_tosu].text.strip())
                    if tm:
                        field_size = int(tm.group(1))

                # â”€â”€ ãƒ¬ãƒ¼ã‚¹çµ±è¨ˆï¼ˆä¸ŠãŒã‚Š3FåŸºæº–å€¤ãƒ»ãƒ©ãƒƒãƒ—ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                race_stats: Dict = {}
                if race_id and last_3f > 0:
                    if race_id in self.race_stats_cache:
                        race_stats = self.race_stats_cache[race_id]
                        self._debug_print(f"    ğŸ“¦ ãƒ¬ãƒ¼ã‚¹çµ±è¨ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {race_id}", "DEBUG")
                    else:
                        time.sleep(0.5)
                        race_stats = self._get_race_last_3f_stats(race_id)
                        if race_stats:
                            self.race_stats_cache[race_id] = race_stats

                lap_times = race_stats.get('lap_times', [])
                late_4f = self._calculate_late_4f_from_laps(lap_times) if lap_times else 0.0
                baba = race_stats.get('baba', 'è‰¯')

                history.append({
                    'date': date,
                    'race_date': date,
                    'course': course_name,
                    'dist': distance,
                    'dist_text': dist_text,
                    'track_type': race_track_type,
                    'baba': baba,
                    'chakujun': chakujun,
                    'chakusa': chakusa_text,
                    'goal_time_diff': goal_time_diff,
                    'goal_sec': goal_sec,
                    'winner_margin': winner_margin if chakujun == 1 else 0.0,
                    'weight': weight,
                    'last_3f': last_3f,
                    'late_4f': late_4f,
                    'race_name': race_name_hist,
                    'race_avg_last_3f': race_stats.get('avg_last_3f', 0.0),
                    'race_min_last_3f': race_stats.get('min_last_3f', 0.0),
                    'race_max_last_3f': race_stats.get('max_last_3f', 0.0),
                    'race_std_last_3f': race_stats.get('std_last_3f', 0.0),
                    'all_horses_results': race_stats.get('all_horses_results', []),
                    'corner_pos': corner_pos,
                    'position_4c': corner_pos,
                    'field_size': field_size,
                })

            except Exception:
                continue

        return history

    def _get_horse_history_cached(self, horse_id: str, horse_name: str,
                                  current_weight: float,
                                  race_distance: int, course: str) -> List[Dict]:
        cached = self._get_from_cache(horse_name)
        if cached is not None:
            return cached
        self.api_calls += 1
        self._debug_print(f"  ğŸŒ APIå‘¼ã³å‡ºã— (é¦¬å: {horse_name})", "DEBUG")
        history = self._get_horse_history(horse_id, current_weight, race_distance, course)
        if history:
            self._save_to_cache(horse_name, history)
        time.sleep(self.scraping_delay)
        return history

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â–¼â–¼â–¼ Scraplingæ›¸ãæ›ãˆï¼šéå»ãƒ¬ãƒ¼ã‚¹çµ±è¨ˆ â–¼â–¼â–¼
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _extract_lap_times(self, page) -> List[float]:
        """
        Scraplingã® find_by_text / css ã§ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‚’æŠ½å‡ºã€‚
        """
        lap_times: List[float] = []

        # æ–¹æ³•1: "ãƒ©ãƒƒãƒ—"ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€è¦ç´ ã‚’æ¢ã™
        for elem in page.find_by_text('ãƒ©ãƒƒãƒ—', case_sensitive=False):
            raw = elem.text.strip()
            times = re.findall(r'\d+\.\d+', raw)
            if times:
                lap_times = [float(t) for t in times]
                break
            # æ¬¡ã®å…„å¼Ÿè¦ç´ ã‚‚ç¢ºèª
            sib = elem.next
            if sib:
                times = re.findall(r'\d+\.\d+', sib.text.strip() if hasattr(sib, 'text') else '')
                if times:
                    lap_times = [float(t) for t in times]
                    break

        if lap_times:
            return lap_times

        # æ–¹æ³•2: ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã§ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‚’æ¢ã™
        for row in page.css('table tr'):
            row_text = row.text.strip()
            if 'ãƒ©ãƒƒãƒ—' in row_text:
                times = re.findall(r'\d+\.\d+', row_text)
                if len(times) >= 4:
                    return [float(t) for t in times]

        # æ–¹æ³•3: divå†…ã‚’æ¢ã™
        for div in page.css('div'):
            div_text = div.text.strip()
            if 'ãƒ©ãƒƒãƒ—' in div_text and '-' in div_text:
                times = re.findall(r'\d+\.\d+', div_text)
                if len(times) >= 4:
                    return [float(t) for t in times]

        return []

    def _calculate_late_4f_from_laps(self, lap_times: List[float]) -> float:
        if not lap_times or len(lap_times) < 4:
            return 0.0
        return round(sum(lap_times[-4:]), 1)

    def _get_race_last_3f_stats(self, race_id: str) -> Dict:
        """
        éå»ãƒ¬ãƒ¼ã‚¹ã®ä¸ŠãŒã‚Š3Fçµ±è¨ˆã‚’å–å¾—ï¼ˆScraplingç‰ˆï¼‰ã€‚
        v6ã¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã€BeautifulSoupã‚’Scraplingã«ç½®ãæ›ãˆã€‚
        """
        url = f"https://db.netkeiba.com/race/{race_id}/"
        try:
            page = self._fetch_page(url, encoding='EUC-JP')
        except Exception:
            return {}

        lap_times = self._extract_lap_times(page)

        # é¦¬å ´çŠ¶æ…‹
        race_data = page.css_first('.RaceData01')
        baba = "è‰¯"
        if race_data:
            t = race_data.text
            if "ä¸è‰¯" in t:
                baba = "ä¸è‰¯"
            elif "ç¨é‡" in t or "ç¨" in t:
                baba = "ç¨é‡"
            elif "é‡" in t and "ç¨" not in t:
                baba = "é‡"

        table = page.css_first('table.race_table_01')
        if not table:
            return {}

        headers = [th.text.strip() for th in table.css('th')]

        def find_col_idx(keywords):
            for kw in keywords:
                for i, h in enumerate(headers):
                    if kw in h:
                        return i
            return -1

        last_3f_idx  = find_col_idx(["ä¸Šã‚Š", "ä¸ŠãŒã‚Š", "3F"])
        chakujun_idx = find_col_idx(["ç€é †", "ç€"])
        time_idx     = find_col_idx(["ã‚¿ã‚¤ãƒ ", "èµ°ç ´ã‚¿ã‚¤ãƒ "])

        if last_3f_idx  == -1: last_3f_idx  = len(headers) - 2
        if chakujun_idx == -1: chakujun_idx = 0
        if time_idx     == -1: time_idx     = 7

        def parse_time_to_sec(t: str) -> Optional[float]:
            t = t.strip()
            if ':' in t:
                parts = t.split(':')
                try:
                    return int(parts[0]) * 60 + float(parts[1])
                except Exception:
                    return None
            try:
                return float(t)
            except Exception:
                return None

        values: List[float] = []
        all_horses_results: List[Dict] = []
        first_place_time: Optional[float] = None

        for row in table.css('tr')[1:]:
            tds = row.css('td')
            if len(tds) <= max(last_3f_idx, chakujun_idx, time_idx):
                continue
            try:
                cm = re.search(r'(\d+)', tds[chakujun_idx].text.strip())
                if not cm:
                    continue
                chakujun = int(cm.group(1))

                goal_sec = parse_time_to_sec(tds[time_idx].text.strip())

                last_3f_raw = re.sub(r"[()ï¼ˆï¼‰]", "", tds[last_3f_idx].text.strip())
                try:
                    last_3f = float(last_3f_raw)
                except Exception:
                    last_3f = 0.0

                if chakujun == 1 and goal_sec:
                    first_place_time = goal_sec

                all_horses_results.append({
                    'chakujun': chakujun,
                    'last_3f': last_3f,
                    'goal_sec': goal_sec,
                    'goal_time_diff': 0.0,
                })

                if 30 < last_3f < 50:
                    values.append(last_3f)
            except Exception:
                continue

        if first_place_time:
            for h in all_horses_results:
                if h['chakujun'] == 1:
                    h['goal_time_diff'] = 0.0
                elif h['goal_sec']:
                    h['goal_time_diff'] = round(h['goal_sec'] - first_place_time, 3)

        if not values:
            return {}

        return {
            'avg_last_3f':    round(statistics.mean(values), 2),
            'min_last_3f':    round(min(values), 2),
            'max_last_3f':    round(max(values), 2),
            'median_last_3f': round(statistics.median(values), 2),
            'std_last_3f':    round(statistics.stdev(values), 2) if len(values) > 1 else 0.0,
            'count':          len(values),
            'all_horses_results': all_horses_results,
            'lap_times': lap_times,
            'baba': baba,
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆv6ã‹ã‚‰æ§‹é€ ç¶™æ‰¿ãƒ»Scraplingå¯¾å¿œï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def check_if_new_horse_race(self, race_name: str) -> Tuple[bool, str]:
        if 'æ–°é¦¬' in race_name:
            return True, f"ãƒ¬ãƒ¼ã‚¹åã«'æ–°é¦¬'ã‚’æ¤œå‡º: {race_name}"
        return False, ""

    def get_race_data(self, race_id: str) -> Dict:
        """ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆScraplingç‰ˆãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        self._debug_print("=" * 70)
        self._debug_print(f"ãƒ¬ãƒ¼ã‚¹ID: {race_id} ã®è§£æã‚’é–‹å§‹")
        stats = self.get_cache_stats()
        self._debug_print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥: é¦¬å{stats['name_cache_size']}ä»¶/ãƒ¬ãƒ¼ã‚¹{stats['race_cache_size']}ä»¶")
        self._debug_print("=" * 70)

        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        course = self._get_course_name(race_id)

        # â”€â”€ ãƒšãƒ¼ã‚¸å–å¾—ï¼ˆScraplingï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            self._debug_print(f"URLã‚¢ã‚¯ã‚»ã‚¹: {url}")
            page = self._fetch_page(url, encoding='EUC-JP')
            self._debug_print("ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ")
        except Exception as e:
            raise Exception(f"ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: {e}")

        # â”€â”€ å–ã‚Šã‚„ã‚ãƒ»404 æ¤œå‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        page_text = page.get_all_text()
        if any(kw in page_text for kw in ['å–ã‚Šã‚„ã‚', 'ä¸­æ­¢', 'ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“']):
            self._debug_print("âš ï¸ ã€ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚æ¤œå‡ºã€‘", "WARNING")
            return {
                "race_name": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚", "distance": 0,
                "track_type": "ä¸æ˜", "course": course,
                "df": pd.DataFrame(), "is_cancelled": True,
                "skip_reason": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚", "debug_logs": self.debug_logs,
            }

        # â”€â”€ ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        race_name, race_distance, track_type, _ = self._get_race_info(page)

        # éšœå®³ãƒ¬ãƒ¼ã‚¹
        if track_type == "éšœå®³":
            self._debug_print("ğŸš« ã€éšœå®³ãƒ¬ãƒ¼ã‚¹æ¤œå‡ºã€‘äºˆæƒ³ã‚’ä¸­æ­¢", "WARNING")
            return {
                "race_name": race_name, "distance": race_distance,
                "track_type": track_type, "course": course,
                "df": pd.DataFrame(), "is_new_horse_race": False,
                "is_éšœå®³_race": True, "skip_reason": "éšœå®³ãƒ¬ãƒ¼ã‚¹",
                "debug_logs": self.debug_logs,
                "message": "éšœå®³ãƒ¬ãƒ¼ã‚¹ã®ãŸã‚äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ",
                "cache_stats": self.get_cache_stats(),
            }

        # æ–°é¦¬æˆ¦
        is_new_horse, reason = self.check_if_new_horse_race(race_name)
        if is_new_horse and self.skip_new_horse:
            self._debug_print("ğŸš« ã€æ–°é¦¬æˆ¦æ¤œå‡ºã€‘äºˆæƒ³ã‚’ä¸­æ­¢", "WARNING")
            return {
                "race_name": race_name, "distance": race_distance,
                "track_type": track_type, "course": course,
                "df": pd.DataFrame(), "is_new_horse_race": True,
                "skip_reason": reason, "debug_logs": self.debug_logs,
                "message": "æ–°é¦¬æˆ¦ã®ãŸã‚äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ",
                "cache_stats": self.get_cache_stats(),
            }

        self._debug_print(f"ã€ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã€‘ãƒ¬ãƒ¼ã‚¹å: {race_name} / ã‚³ãƒ¼ã‚¹: {course} / "
                          f"è·é›¢: {race_distance}m / é¦¬å ´: {track_type}")

        # â”€â”€ å‡ºé¦¬è¡¨è§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        horse_data = self._parse_shutuba(page)

        if not horse_data:
            raise Exception("å‡ºé¦¬è¡¨ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        # ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        horse_names = [h['é¦¬å'] for h in horse_data]
        cached_df = self._check_race_cache(race_name, horse_names)
        if cached_df is not None:
            if 'ç·åˆæŒ‡æ•°' in cached_df.columns:
                cached_df = cached_df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
            if 'æŒ‡æ•°' not in cached_df.columns:
                cached_df['æŒ‡æ•°'] = 0.0
            return {
                "race_name": race_name, "distance": race_distance,
                "track_type": track_type, "course": course,
                "df": cached_df, "is_new_horse_race": False,
                "from_cache": True, "debug_logs": self.debug_logs,
                "cache_stats": self.get_cache_stats(),
            }

        df = pd.DataFrame(horse_data)
        df["æŒ‡æ•°"] = 0.0

        # â”€â”€ å…¨é¦¬ã®å±¥æ­´ä¸€æ‹¬å–å¾—ï¼‹è„šè³ªåˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._debug_print(f"ã€é¦¬ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—ï¼‹è„šè³ªåˆ†æã€‘å…¨{len(df)}é ­...")
        all_running_styles: List[Dict] = []
        horse_histories: Dict[int, List[Dict]] = {}

        for index, row in df.iterrows():
            if self.progress_callback:
                self.progress_callback(row['é¦¬å'], index + 1, len(df))
            if row.get("horse_id"):
                history = self._get_horse_history_cached(
                    row["horse_id"], row["é¦¬å"],
                    row["æ–¤é‡"], race_distance, course
                )
                horse_histories[index] = history
                running_style = self._extract_running_style_from_history(history)
                if running_style:
                    all_running_styles.append(running_style)
                    self._debug_print(f"  {row['é¦¬å']:12s}: {running_style['style']} "
                                      f"(ä¿¡é ¼åº¦{running_style['confidence']:.2f})")

        # â”€â”€ ãƒšãƒ¼ã‚¹äºˆæ¸¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        field_size = len(df)
        pace_prediction = (
            self._predict_race_pace(all_running_styles, field_size, course)
            if all_running_styles else None
        )

        if pace_prediction:
            self._debug_print(f"ã€ãƒšãƒ¼ã‚¹äºˆæ¸¬ã€‘{pace_prediction['pace']} / "
                              f"å‰æ®‹ã‚Šç‡: {pace_prediction['front_ratio']:.1%}")

        # â”€â”€ ã‚¹ã‚³ã‚¢è¨ˆç®— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for index, row in df.iterrows():
            if not row.get("horse_id"):
                continue
            history = horse_histories.get(index, [])
            self._debug_print(f"ã€{row['é¦¬å']}ã€‘åˆ†æé–‹å§‹ (éå»{len(history)}èµ°)")
            if not history:
                df.at[index, "æŒ‡æ•°"] = 0.0
                continue

            running_style_info = self._extract_running_style_from_history(history)
            horse_age, horse_sex = self._parse_sex_age(row.get("æ€§é½¢", ""))

            analysis = self.scorer.calculate_total_score(
                current_weight=row["æ–¤é‡"],
                target_course=course,
                target_distance=race_distance,
                history_data=history,
                target_track_type=track_type,
                running_style_info=running_style_info,
                race_pace_prediction=pace_prediction,
                horse_age=horse_age,
                horse_sex=horse_sex,
            )
            df.at[index, "æŒ‡æ•°"] = analysis["total_score"]

            breakdown_text = self.scorer.format_score_breakdown_verbose(
                result=analysis,
                target_distance=race_distance,
                history_data=history,
                current_weight=row["æ–¤é‡"],
                target_course=course,
                target_track_type=track_type,
                running_style_info=running_style_info,
                race_pace_prediction=pace_prediction,
                horse_age=horse_age,
                horse_sex=horse_sex,
            )
            for line in breakdown_text.split('\n'):
                self._debug_print(f"  {line}")

        # â”€â”€ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»å° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df = df.sort_values("æŒ‡æ•°", ascending=False).reset_index(drop=True)
        marks = []
        for i, row in df.iterrows():
            is_dangerous = row["æŒ‡æ•°"] <= 0
            if is_dangerous:
                mark = "Ã—" if i <= 5 else ""
            elif i == 0:
                mark = "â—"
            elif i == 1:
                mark = "â—‹"
            elif i == 2:
                mark = "â–²"
            elif i <= 5:
                mark = "â–³"
            else:
                mark = ""
            marks.append(mark)
            self._debug_print(f"  {i+1:2d}ä½ {'âš ï¸' if is_dangerous else '  '} {mark:4s} "
                              f"é¦¬ç•ª{row['é¦¬ç•ª']:>2s} {row['é¦¬å']:12s} "
                              f"æŒ‡æ•°:{row['æŒ‡æ•°']:6.1f} æ–¤é‡:{row['æ–¤é‡']:4.1f}kg")
        df["å°"] = marks

        # åˆ—åçµ±ä¸€ï¼ˆé˜²å¾¡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼‰
        if 'ç·åˆæŒ‡æ•°' in df.columns:
            df = df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
        if 'æŒ‡æ•°' not in df.columns:
            df['æŒ‡æ•°'] = 0.0

        self._save_race_cache(race_name, df)

        return {
            "race_name": race_name,
            "distance": race_distance,
            "track_type": track_type,
            "course": course,
            "df": df,
            "is_new_horse_race": False,
            "from_cache": False,
            "debug_logs": self.debug_logs,
            "cache_stats": self.get_cache_stats(),
        }


if __name__ == "__main__":
    print("âœ… NetkeibaRaceScraper v7ï¼ˆScraplingå¯¾å¿œç‰ˆï¼‰loaded")
