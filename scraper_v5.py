"""
ç«¶é¦¬äºˆæƒ³AI - scraper_v5.pyï¼ˆenhanced_scorer_v7å¯¾å¿œç‰ˆï¼‰
æœ€çµ‚æ›´æ–°: 2026å¹´2æœˆ22æ—¥

ä¸»ãªå¤‰æ›´ç‚¹ (v4â†’v5):
- enhanced_scorer_v7 ã«å¯¾å¿œï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤‰æ›´ï¼‰
- éå»æˆ¦ç¸¾å–å¾—ã‚’5èµ°â†’7è¡Œã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—ã«å¤‰æ›´ï¼ˆä¸­æ­¢é™¤å¤–ã‚¹ã‚­ãƒƒãƒ—è¾¼ã¿ã§5èµ°ç¢ºä¿ï¼‰

ä¸»ãªæ©Ÿèƒ½:
1. enhanced_scorer_v6ã®å…¨æ©Ÿèƒ½ã«å¯¾å¿œ:
   - æ–°é¦¬æˆ¦2æˆ¦ç›®ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆç€é †åˆ¥ãƒœãƒ¼ãƒŠã‚¹ï¼‰
   - é€£ç¶šå¤§æ•—ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆè»½æ¸›æ¡ä»¶ä»˜ãï¼‰
   - é‡è³å‡ºèµ°ãƒœãƒ¼ãƒŠã‚¹
   - é•·æœŸä¼‘é¤ŠãƒšãƒŠãƒ«ãƒ†ã‚£
   - è„šè³ªÃ—å±•é–‹Ã—ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®é©åˆåº¦
   - å¾ŒåŠ4Fè©•ä¾¡ï¼ˆèŠä¸­é•·è·é›¢ï¼‰
   - æ–¤é‡Ã—ã‚¿ã‚¤ãƒ è©•ä¾¡ï¼ˆçŸ­è·é›¢ï¼‰
2. è„šè³ªåˆ†æï¼ˆé€šéé †ä½ã‹ã‚‰è‡ªå‹•åˆ¤å®šï¼‰
3. ãƒšãƒ¼ã‚¹äºˆæ¸¬ï¼ˆå‡ºèµ°é ­æ•°ãƒ»é€ƒã’é¦¬ã®è³ªã‚’è€ƒæ…®ï¼‰
4. ã‚¹ã‚³ã‚¢å†…è¨³ã®è¦‹ã‚„ã™ã„è¡¨ç¤º
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import logging
import statistics
from typing import List, Dict, Optional, Tuple
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from enhanced_scorer_v7 import RaceScorer
except ImportError as e:
    logger.error(f"Import error: {e}")
    raise ImportError("enhanced_scorer_v7.py ãŒå¿…è¦ã§ã™")


class NetkeibaRaceScraper:
    """netkeibaã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v4ï¼ˆenhanced_scorer_v6å¯¾å¿œç‰ˆï¼‰"""
    
    def __init__(self, scraping_delay: float = 1.0, debug_mode: bool = False):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.scorer = RaceScorer(debug_mode=debug_mode)
        self.scraping_delay = scraping_delay
        self.debug_mode = debug_mode
        self.debug_logs = []
        self.skip_new_horse = True  # æ–°é¦¬æˆ¦ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        self.cache_hits = 0
        self.api_calls = 0
        self.progress_callback = None  # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

    def _extract_running_style_from_history(self, history: List[Dict]) -> Optional[Dict]:
        """
        éå»æˆ¦ç¸¾ã‹ã‚‰è„šè³ªã‚’åˆ¤å®š
        
        Args:
            history: éå»æˆ¦ç¸¾ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            {'style': 'é€ƒã’', 'confidence': 0.85, ...} or None
        """
        if not history:
            return None
        
        # å„ãƒ¬ãƒ¼ã‚¹ã®è„šè³ªã‚’åˆ¤å®š
        styles = []
        
        for race in history[:5]:  # ç›´è¿‘5èµ°ã‚’ä½¿ç”¨
            corner_pos = race.get('corner_pos', 0) or race.get('position_4c', 0)
            field_size = race.get('field_size', 16)
            last_3f = race.get('last_3f', 0.0)
            race_avg_3f = race.get('race_avg_last_3f', 0.0)
            
            if corner_pos > 0 and field_size > 0:
                # å„ãƒ¬ãƒ¼ã‚¹ã®è„šè³ªã‚’åˆ¤å®š
                style_info = self.scorer.style_analyzer.classify_running_style(
                    position_4c=corner_pos,
                    field_size=field_size,
                    last_3f=last_3f,
                    race_avg_3f=race_avg_3f
                )
                
                if style_info and style_info.get('style') != 'ä¸æ˜':
                    styles.append(style_info)
        
        if not styles:
            return None
        
        # æœ€é »å‡ºã®è„šè³ªã‚’æ¡ç”¨
        from collections import Counter
        style_counts = Counter(s['style'] for s in styles)
        most_common_style = style_counts.most_common(1)[0][0]
        
        # è©²å½“ã™ã‚‹è„šè³ªã®å¹³å‡ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        matching_styles = [s for s in styles if s['style'] == most_common_style]
        avg_confidence = sum(s['confidence'] for s in matching_styles) / len(matching_styles)
        
        # ä¸€è²«æ€§ãƒœãƒ¼ãƒŠã‚¹ï¼ˆåŒã˜è„šè³ªãŒå¤šã„ã»ã©ä¿¡é ¼åº¦ãŒä¸ŠãŒã‚‹ï¼‰
        consistency = len(matching_styles) / len(styles)
        final_confidence = avg_confidence * (0.7 + 0.3 * consistency)
        
        return {
            'style': most_common_style,
            'confidence': min(final_confidence, 0.95)
        }
    
    def _predict_race_pace(self, horses_running_styles: List[Dict], field_size: int, course: str = 'æ±äº¬') -> Dict:
        """
        ãƒ¬ãƒ¼ã‚¹å…¨ä½“ã®ãƒšãƒ¼ã‚¹ã‚’äºˆæ¸¬
        
        Args:
            horses_running_styles: å„é¦¬ã®è„šè³ªæƒ…å ±ãƒªã‚¹ãƒˆ
            field_size: å‡ºèµ°é ­æ•°
            course: ã‚³ãƒ¼ã‚¹å
            
        Returns:
            {'pace': 'ãƒã‚¤'/'ãƒŸãƒ‰ãƒ«'/'ã‚¹ãƒ­ãƒ¼', ...}
        """
        if not horses_running_styles:
            return {'pace': 'ãƒŸãƒ‰ãƒ«', 'front_ratio': 0.30}
        
        # RaceScorerã®ãƒšãƒ¼ã‚¹äºˆæ¸¬æ©Ÿèƒ½ã‚’ä½¿ç”¨
        pace_result = self.scorer.style_analyzer.predict_race_pace(
            horses_running_styles, field_size, course
        )
        
        # è„šè³ªã®åˆ†å¸ƒã‚’è¨ˆç®—
        from collections import Counter
        style_counts = Counter(h.get('style', 'ä¸æ˜') for h in horses_running_styles if h.get('style') != 'ä¸æ˜')
        pace_result['distribution'] = {
            'é€ƒã’': style_counts.get('é€ƒã’', 0),
            'å…ˆè¡Œ': style_counts.get('å…ˆè¡Œ', 0),
            'å·®ã—': style_counts.get('å·®ã—', 0),
            'è¿½è¾¼': style_counts.get('è¿½è¾¼', 0)
        }
        
        return pace_result

    def _init_session_state(self):
        """Streamlitã®session_stateã‚’åˆæœŸåŒ–"""
        try:
            import streamlit as st
            if 'horse_cache_by_name' not in st.session_state:
                st.session_state.horse_cache_by_name = {}
            if 'race_cache' not in st.session_state:
                st.session_state.race_cache = {}
            return True
        except ImportError:
            return False

    def _get_cache_key_by_name(self, horse_name: str) -> str:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼"""
        normalized = re.sub(r'\s+', '', horse_name).lower()
        return normalized
    
    def _parse_sex_age(self, sex_age_str: str) -> Tuple[Optional[int], Optional[str]]:
        """
        æ€§é½¢æ–‡å­—åˆ—ã‚’è§£æ
        
        Args:
            sex_age_str: æ€§é½¢æ–‡å­—åˆ—ï¼ˆä¾‹: "ç‰¡4", "ç‰5", "ã‚»7"ï¼‰
        
        Returns:
            (å¹´é½¢, æ€§åˆ¥) ã®ã‚¿ãƒ—ãƒ«ï¼ˆä¾‹: (4, "ç‰¡"), (5, "ç‰")ï¼‰
        """
        if not sex_age_str:
            return None, None
        
        # å…¨è§’æ•°å­—ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ­£è¦åŒ–
        import unicodedata
        normalized = unicodedata.normalize('NFKC', sex_age_str).replace(' ', '').replace('\u3000', '')

        # æ­£è¦è¡¨ç¾ã§æ€§åˆ¥ã¨å¹´é½¢ã‚’æŠ½å‡º
        match = re.match(r'^([ç‰¡ç‰ã‚»])(\d{1,2})$', normalized)
        if match:
            sex = match.group(1)
            age = int(match.group(2))
            return age, sex

        return None, None

    def _get_from_cache(self, horse_name: str) -> Optional[List[Dict]]:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        if not self._init_session_state():
            return None
        
        try:
            import streamlit as st
            cache_key = self._get_cache_key_by_name(horse_name)
            if cache_key in st.session_state.horse_cache_by_name:
                self.cache_hits += 1
                self._debug_print(f"  ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ(é¦¬å): {horse_name}", "DEBUG")
                return st.session_state.horse_cache_by_name[cache_key]
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None

    def _save_to_cache(self, horse_name: str, data: List[Dict]):
        """é¦¬åãƒ™ãƒ¼ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
        if not self._init_session_state():
            return
        
        try:
            import streamlit as st
            cache_key = self._get_cache_key_by_name(horse_name)
            st.session_state.horse_cache_by_name[cache_key] = data
            self._debug_print(f"  ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜(é¦¬å): {horse_name}", "DEBUG")
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _check_race_cache(self, race_name: str, horse_names: List[str]) -> Optional[pd.DataFrame]:
        """åŒã˜ãƒ¬ãƒ¼ã‚¹åãƒ»åŒã˜é¦¬ã®çµ„ã¿åˆã‚ã›ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self._init_session_state():
            return None
        
        try:
            import streamlit as st
            
            race_key = re.sub(r'\s+', '', race_name).lower()
            horse_set = set(self._get_cache_key_by_name(h) for h in horse_names)
            
            for cached_race, cached_df in st.session_state.race_cache.items():
                if cached_race == race_key:
                    cached_horses = set(self._get_cache_key_by_name(h) for h in cached_df['é¦¬å'].tolist())
                    if horse_set == cached_horses:
                        self._debug_print(f"ğŸ“¦ ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {race_name}", "INFO")
                        return cached_df
            
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None

    def _save_race_cache(self, race_name: str, df: pd.DataFrame):
        """ãƒ¬ãƒ¼ã‚¹çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        if not self._init_session_state():
            return
        
        try:
            import streamlit as st
            race_key = re.sub(r'\s+', '', race_name).lower()
            st.session_state.race_cache[race_key] = df.copy()
            self._debug_print(f"ğŸ’¾ ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {race_name}", "INFO")
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def get_cache_stats(self) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—"""
        try:
            import streamlit as st
            name_cache_size = len(st.session_state.get('horse_cache_by_name', {}))
            race_cache_size = len(st.session_state.get('race_cache', {}))
        except:
            name_cache_size = 0
            race_cache_size = 0
        
        total = self.cache_hits + self.api_calls
        return {
            'name_cache_size': name_cache_size,
            'race_cache_size': race_cache_size,
            'cache_hits': self.cache_hits,
            'api_calls': self.api_calls,
            'hit_rate': (self.cache_hits / total * 100) if total > 0 else 0
        }

    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        try:
            import streamlit as st
            st.session_state.horse_cache_by_name = {}
            st.session_state.race_cache = {}
            self.cache_hits = 0
            self.api_calls = 0
            logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def _debug_print(self, message: str, level: str = "INFO"):
        """ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        
        if self.debug_mode:
            print(log_entry)
        
        self.debug_logs.append(log_entry)
        if level == "ERROR":
            logger.error(message)
        elif level == "WARNING":
            logger.warning(message)
        else:
            logger.info(message)

    def check_if_new_horse_race(self, soup: BeautifulSoup, race_name: str = "") -> Tuple[bool, str]:
        """æ–°é¦¬æˆ¦ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆãƒ¬ãƒ¼ã‚¹åã®ã¿ã§åˆ¤æ–­ï¼‰"""
        # ãƒ¬ãƒ¼ã‚¹åã«ã€Œæ–°é¦¬ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—
        # ã€Œ2æ­³æ–°é¦¬ã€ã€Œ3æ­³æ–°é¦¬ã€ãªã©
        if 'æ–°é¦¬' in race_name:
            return True, f"ãƒ¬ãƒ¼ã‚¹åã«'æ–°é¦¬'ã‚’æ¤œå‡º: {race_name}"
        
        # ã€Œæœªå‹åˆ©ã€ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„
        return False, ""

    def get_race_data(self, race_id: str) -> Dict:
        """ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        self._debug_print(f"=" * 70)
        self._debug_print(f"ãƒ¬ãƒ¼ã‚¹ID: {race_id} ã®è§£æã‚’é–‹å§‹")
        stats = self.get_cache_stats()
        self._debug_print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥: é¦¬å{stats['name_cache_size']}ä»¶/ãƒ¬ãƒ¼ã‚¹{stats['race_cache_size']}ä»¶")
        self._debug_print(f"=" * 70)
        
        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        
        try:
            self._debug_print(f"URLã‚¢ã‚¯ã‚»ã‚¹: {url}")
            response = self.session.get(url, timeout=15)
            
            # ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚ãƒ»404ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡º
            if response.status_code == 404:
                self._debug_print(f"")
                self._debug_print(f"âš ï¸ ã€ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚æ¤œå‡ºã€‘ã“ã®ãƒ¬ãƒ¼ã‚¹ã¯å­˜åœ¨ã—ã¾ã›ã‚“", "WARNING")
                self._debug_print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: 404", "WARNING")
                self._debug_print(f"")
                return {
                    "race_name": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "distance": 0,
                    "track_type": "ä¸æ˜",
                    "course": self._get_course_name(race_id),
                    "df": pd.DataFrame(),
                    "is_cancelled": True,
                    "skip_reason": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚ï¼ˆ404ã‚¨ãƒ©ãƒ¼ï¼‰",
                    "debug_logs": self.debug_logs,
                }
            
            response.raise_for_status()
            response.encoding = 'EUC-JP'
            soup = BeautifulSoup(response.content, "html.parser", from_encoding='EUC-JP')
            self._debug_print("ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ")
            
            # ãƒšãƒ¼ã‚¸å†…å®¹ã§å–ã‚Šã‚„ã‚ãƒã‚§ãƒƒã‚¯
            page_text = soup.get_text()
            if 'å–ã‚Šã‚„ã‚' in page_text or 'ä¸­æ­¢' in page_text or 'ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“' in page_text:
                self._debug_print(f"")
                self._debug_print(f"âš ï¸ ã€ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚æ¤œå‡ºã€‘ãƒšãƒ¼ã‚¸å†…ã«å–ã‚Šã‚„ã‚è¡¨ç¤º", "WARNING")
                self._debug_print(f"")
                return {
                    "race_name": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "distance": 0,
                    "track_type": "ä¸æ˜",
                    "course": self._get_course_name(race_id),
                    "df": pd.DataFrame(),
                    "is_cancelled": True,
                    "skip_reason": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "debug_logs": self.debug_logs,
                }
                
        except Exception as e:
            raise Exception(f"ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: {e}")

        race_name = self._get_race_name(soup)
        race_distance = self._get_race_distance(soup)
        track_type = self._get_track_type(soup)
        course = self._get_course_name(race_id)

        # éšœå®³ãƒ¬ãƒ¼ã‚¹åˆ¤å®šï¼ˆäºˆæƒ³å¯¾è±¡å¤–ï¼‰
        if track_type == "éšœå®³":
            self._debug_print(f"")
            self._debug_print(f"ğŸš« ã€éšœå®³ãƒ¬ãƒ¼ã‚¹æ¤œå‡ºã€‘äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã™", "WARNING")
            self._debug_print(f"   ãƒ¬ãƒ¼ã‚¹å: {race_name}", "WARNING")
            self._debug_print(f"   éšœå®³ãƒ¬ãƒ¼ã‚¹ã¯å¹³åœ°ã¨ãƒ«ãƒ¼ãƒ«ãŒç•°ãªã‚‹ãŸã‚äºˆæƒ³å¯¾è±¡å¤–ã§ã™", "WARNING")
            self._debug_print(f"")
            return {
                "race_name": race_name,
                "distance": race_distance,
                "track_type": track_type,
                "course": course,
                "df": pd.DataFrame(),
                "is_new_horse_race": False,
                "is_éšœå®³_race": True,
                "skip_reason": "éšœå®³ãƒ¬ãƒ¼ã‚¹",
                "debug_logs": self.debug_logs,
                "message": "éšœå®³ãƒ¬ãƒ¼ã‚¹ã®ãŸã‚äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ",
                "cache_stats": self.get_cache_stats()
            }

        # æ–°é¦¬æˆ¦åˆ¤å®š
        is_new_horse, reason = self.check_if_new_horse_race(soup, race_name)
        
        if is_new_horse and self.skip_new_horse:
            self._debug_print(f"")
            self._debug_print(f"ğŸš« ã€æ–°é¦¬æˆ¦æ¤œå‡ºã€‘äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã™", "WARNING")
            self._debug_print(f"   ç†ç”±: {reason}", "WARNING")
            self._debug_print(f"   ãƒ¬ãƒ¼ã‚¹å: {race_name}", "WARNING")
            self._debug_print(f"")
            
            return {
                "race_name": race_name,
                "distance": race_distance,
                "track_type": track_type,
                "course": course,
                "df": pd.DataFrame(),
                "is_new_horse_race": True,
                "skip_reason": reason,
                "debug_logs": self.debug_logs,
                "message": "æ–°é¦¬æˆ¦ã®ãŸã‚äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ",
                "cache_stats": self.get_cache_stats()
            }

        self._debug_print(f"")
        self._debug_print(f"ã€ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã€‘")
        self._debug_print(f"  ãƒ¬ãƒ¼ã‚¹å: {race_name}")
        self._debug_print(f"  ã‚³ãƒ¼ã‚¹: {course}")
        self._debug_print(f"  è·é›¢: {race_distance}m")
        self._debug_print(f"  é¦¬å ´: {track_type}")
        self._debug_print(f"")

        horse_data = self._parse_shutuba(soup)
        
        self._debug_print(f"ã€å–å¾—ã—ãŸé¦¬ãƒ‡ãƒ¼ã‚¿ã€‘")
        for i, h in enumerate(horse_data, 1):
            self._debug_print(f"  {i}. é¦¬ç•ª{h.get('é¦¬ç•ª', '?')} {h.get('é¦¬å', 'ä¸æ˜')} | "
                            f"æ–¤é‡:{h.get('æ–¤é‡', '?')}kg | é¨æ‰‹:{h.get('é¨æ‰‹', '?')}")
        self._debug_print(f"")
        
        if not horse_data:
            raise Exception("å‡ºé¦¬è¡¨ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        # ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        horse_names = [h['é¦¬å'] for h in horse_data]
        cached_df = self._check_race_cache(race_name, horse_names)
        
        if cached_df is not None:
            self._debug_print(f"âœ… åŒä¸€ãƒ¬ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å†åˆ©ç”¨ã—ã¾ã™", "INFO")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™æ™‚ã‚‚åˆ—åã‚’ä¿è¨¼
            if 'ç·åˆæŒ‡æ•°' in cached_df.columns:
                cached_df = cached_df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
            if 'æŒ‡æ•°' not in cached_df.columns:
                cached_df['æŒ‡æ•°'] = 0.0
            
            return {
                "race_name": race_name,
                "distance": race_distance,
                "track_type": track_type,
                "course": course,
                "df": cached_df,
                "is_new_horse_race": False,
                "from_cache": True,
                "debug_logs": self.debug_logs,
                "cache_stats": self.get_cache_stats()
            }

        self._debug_print(f"ğŸ´ {len(horse_data)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
        self._debug_print(f"")

        df = pd.DataFrame(horse_data)
        df["æŒ‡æ•°"] = 0.0
        
        # ã€æ–°æ©Ÿèƒ½ã€‘å…¨é¦¬ã®è„šè³ªã‚’äº‹å‰ã«åˆ†æã—ã¦ãƒšãƒ¼ã‚¹äºˆæ¸¬
        all_running_styles = []
        self._debug_print(f"ã€è„šè³ªåˆ†æã€‘å…¨{len(df)}é ­ã®è„šè³ªã‚’åˆ¤å®šä¸­...")
        
        for index, row in df.iterrows():
            if row.get("horse_id"):
                history = self._get_horse_history_cached(
                    row["horse_id"],
                    row["é¦¬å"],
                    row["æ–¤é‡"],
                    race_distance,
                    course
                )
                running_style = self._extract_running_style_from_history(history)
                if running_style:
                    all_running_styles.append(running_style)
                    self._debug_print(f"  {row['é¦¬å']:12s}: {running_style['style']} (ä¿¡é ¼åº¦{running_style['confidence']:.2f})")
        
        # ãƒšãƒ¼ã‚¹äºˆæ¸¬
        field_size = len(df)
        pace_prediction = self._predict_race_pace(all_running_styles, field_size, course) if all_running_styles else None
        
        if pace_prediction:
            self._debug_print(f"")
            self._debug_print(f"ã€ãƒšãƒ¼ã‚¹äºˆæ¸¬ã€‘")
            self._debug_print(f"  äºˆæƒ³ãƒšãƒ¼ã‚¹: {pace_prediction['pace']}")
            self._debug_print(f"  å‰æ®‹ã‚Šç‡: {pace_prediction['front_ratio']:.1%}")
            self._debug_print(f"  é€ƒã’: {pace_prediction['distribution']['é€ƒã’']}é ­ / "
                            f"å…ˆè¡Œ: {pace_prediction['distribution']['å…ˆè¡Œ']}é ­ / "
                            f"å·®ã—: {pace_prediction['distribution']['å·®ã—']}é ­ / "
                            f"è¿½è¾¼: {pace_prediction['distribution']['è¿½è¾¼']}é ­")
            self._debug_print(f"  ç›´ç·šé•·: {pace_prediction.get('straight_length', 400)}m")
        
        self._debug_print(f"")

        for index, row in df.iterrows():
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—
            if self.progress_callback:
                self.progress_callback(row['é¦¬å'], index + 1, len(df))
            
            if row.get("horse_id"):
                self._debug_print(f"-" * 60)
                self._debug_print(f"ã€{row['é¦¬å']}ã€‘(é¦¬ç•ª:{row['é¦¬ç•ª']}) åˆ†æé–‹å§‹")
                self._debug_print(f"  æ–¤é‡: {row['æ–¤é‡']}kg | é¨æ‰‹: {row['é¨æ‰‹']}")
                
                history = self._get_horse_history_cached(
                    row["horse_id"],
                    row["é¦¬å"],
                    row["æ–¤é‡"],
                    race_distance,
                    course
                )
                
                if history:
                    self._debug_print(f"  éå»æˆ¦ç¸¾: {len(history)}ãƒ¬ãƒ¼ã‚¹å–å¾—")
                    for idx, race in enumerate(history[:5], 1):
                        last_3f = race.get('last_3f', 0)
                        race_avg = race.get('race_avg_last_3f', 0)
                        
                        dist = race.get('dist', 1600)
                        if race_avg <= 0:
                            if dist <= 1400:
                                race_avg = 34.5
                            elif dist <= 1800:
                                race_avg = 35.0
                            elif dist <= 2200:
                                race_avg = 36.0
                            else:
                                race_avg = 37.0
                        
                        is_fast = last_3f > 0 and last_3f < race_avg
                        fast_mark = "â—¯" if is_fast else " "
                        
                        weight = race.get('weight', 0)
                        weight_mark = "â˜…" if weight >= 57.0 else " " if weight >= 55.0 else ""
                        
                        goal_diff = race.get('goal_time_diff', 0.0)
                        big_loss_mark = "ğŸ’€" if goal_diff >= 1.1 else ""
                        self._debug_print(f"    {idx}èµ°å‰: {race.get('race_name', 'ä¸æ˜')[:15]:15s} | "
                                        f"{race.get('dist', '?')}m | "
                                        f"ç€é †:{race.get('chakujun', '?'):>2}ç€ | "
                                        f"æ–¤é‡:{weight:>4.1f}kg{weight_mark} | "
                                        f"ä¸ŠãŒã‚Š3F:{last_3f:>5.1f}s ({fast_mark}åŸºæº–{race_avg:.1f}s) | "
                                        f"ç€å·®:{goal_diff:.2f}s{big_loss_mark}")
                else:
                    self._debug_print(f"  âš ï¸ éå»æˆ¦ç¸¾ãªã—ï¼ˆæ–°é¦¬ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                
                if history:
                    # ã€æ–°æ©Ÿèƒ½ã€‘ã“ã®é¦¬ã®è„šè³ªã‚’å–å¾—
                    running_style_info = self._extract_running_style_from_history(history)
                    
                    # æ€§é½¢ã‚’è§£æï¼ˆä¾‹: "ç‰¡4" â†’ æ€§åˆ¥="ç‰¡", å¹´é½¢=4ï¼‰
                    sex_age_raw = row.get("æ€§é½¢", "")
                    horse_age, horse_sex = self._parse_sex_age(sex_age_raw)
                    if horse_age is None:
                        self._debug_print(f"  âš ï¸ æ€§é½¢ãƒ‘ãƒ¼ã‚¹å¤±æ•—: '{sex_age_raw}' â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯58kgé©ç”¨", "WARNING")
                    else:
                        self._debug_print(f"  æ€§é½¢: {horse_sex}{horse_age}æ­³ â†’ æ–¤é‡åŸºæº–è‡ªå‹•è¨­å®š", "DEBUG")
                    
                    analysis = self.scorer.calculate_total_score(
                        current_weight=row["æ–¤é‡"],
                        target_course=course,
                        target_distance=race_distance,
                        history_data=history,
                        target_track_type=track_type,
                        running_style_info=running_style_info,
                        race_pace_prediction=pace_prediction,
                        horse_age=horse_age,
                        horse_sex=horse_sex
                    )
                    
                    df.at[index, "æŒ‡æ•°"] = analysis["total_score"]
                    
                    # ã€æ–°æ©Ÿèƒ½ã€‘format_score_breakdown_verboseã‚’ä½¿ç”¨ï¼ˆè©³ç´°ç‰ˆï¼‰
                    breakdown_text = self.scorer.format_score_breakdown_verbose(
                        result=analysis,
                        target_distance=race_distance,
                        history_data=history,
                        current_weight=row["æ–¤é‡"],
                        target_course=course,
                        target_track_type=track_type,
                        running_style_info=running_style_info,
                        race_pace_prediction=pace_prediction,
                        horse_age=horse_age,
                        horse_sex=horse_sex,
                    )
                    for line in breakdown_text.split('\n'):
                        self._debug_print(f"  {line}")
                else:
                    df.at[index, "æŒ‡æ•°"] = 0.0
                    self._debug_print(f"  âš ï¸ éå»æˆ¦ç¸¾ãªã—ã®ãŸã‚0ç‚¹")
                
                time.sleep(self.scraping_delay)

        df = df.sort_values("æŒ‡æ•°", ascending=False).reset_index(drop=True)
        
        # æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        self._debug_print(f"")
        self._debug_print(f"=" * 70)
        self._debug_print(f"ã€æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘")
        stats = self.get_cache_stats()
        self._debug_print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: é¦¬å{stats['name_cache_size']}ä»¶/ãƒ¬ãƒ¼ã‚¹{stats['race_cache_size']}ä»¶/ãƒ’ãƒƒãƒˆç‡{stats['hit_rate']:.1f}%")
        self._debug_print(f"=" * 70)
        
        marks = []
        for i, row in df.iterrows():
            is_dangerous = row["æŒ‡æ•°"] <= 0
            
            if is_dangerous:
                mark = "Ã—" if i <= 5 else ""
            elif i == 0:
                mark = "â—"
            elif i == 1:
                mark = "â—‹"
            elif i == 2:
                mark = "â–²"
            elif i <= 5:
                mark = "â–³"
            else:
                mark = ""
            
            marks.append(mark)
            
            danger_mark = "âš ï¸" if is_dangerous else "  "
            self._debug_print(f"  {i+1:2d}ä½ {danger_mark} {mark:4s} é¦¬ç•ª{row['é¦¬ç•ª']:>2s} {row['é¦¬å']:12s} "
                            f"æŒ‡æ•°:{row['æŒ‡æ•°']:6.1f} æ–¤é‡:{row['æ–¤é‡']:4.1f}kg")
        self._debug_print(f"=" * 70)
        
        df["å°"] = marks

        # ãƒ¬ãƒ¼ã‚¹çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._save_race_cache(race_name, df)

        # ============================================================
        # ã€é‡è¦ã€‘åˆ—åã‚’ç¢ºå®Ÿã«'æŒ‡æ•°'ã«çµ±ä¸€ï¼ˆé˜²å¾¡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼‰
        # ============================================================
        if 'ç·åˆæŒ‡æ•°' in df.columns:
            df = df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
        
        if 'æŒ‡æ•°' not in df.columns:
            df['æŒ‡æ•°'] = 0.0
        # ============================================================

        return {
            "race_name": race_name,
            "distance": race_distance,
            "track_type": track_type,
            "course": course,
            "df": df,
            "is_new_horse_race": False,
            "from_cache": False,
            "debug_logs": self.debug_logs,
            "cache_stats": self.get_cache_stats()
        }

    def _get_horse_history_cached(self, horse_id: str, horse_name: str,
                                  current_weight: float,
                                  race_distance: int, course: str) -> List[Dict]:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé¦¬ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        cached_data = self._get_from_cache(horse_name)
        if cached_data is not None:
            return cached_data
        
        self.api_calls += 1
        self._debug_print(f"  ğŸŒ APIå‘¼ã³å‡ºã— (é¦¬å: {horse_name})", "DEBUG")
        history = self._get_horse_history(horse_id, current_weight, race_distance, course)
        
        if history:
            self._save_to_cache(horse_name, history)
        
        return history

        
        # ã¾ãšç›´æ¥floatå¤‰æ›ã‚’è©¦ã¿ã‚‹
        try:
            return float(text)
        except ValueError:
            pass
        
        # æ—¥æœ¬èªç‰¹æ®Šè¡¨è¨˜
        text = text.replace("\u3000", " ").strip()
        special = {
            "ãƒãƒŠ": 0.05, "ã¯ãª": 0.05,
            "ã‚¯ãƒ“": 0.15, "ãã³": 0.15,
            "ã‚¢ã‚¿ãƒ": 0.10, "ã‚ãŸã¾": 0.10,
            "å¤§å·®": 2.5, "ã ã„ã•": 2.5,
        }
        for k, v in special.items():
            if k in text:
                return v
        
        # åˆ†æ•°è¡¨è¨˜ "1/2", "3/4", "1 1/2" ãªã©
        import re as _re
        frac_pattern = _re.match(r'^(\d+)\s+(\d+)/(\d+)$', text)  # "1 1/2"
        if frac_pattern:
            whole = int(frac_pattern.group(1))
            num = int(frac_pattern.group(2))
            den = int(frac_pattern.group(3))
            return round((whole + num / den) * 0.6, 2)
        
        frac_only = _re.match(r'^(\d+)/(\d+)$', text)  # "1/2", "3/4"
        if frac_only:
            num = int(frac_only.group(1))
            den = int(frac_only.group(2))
            return round((num / den) * 0.6, 2)
        
        # æ•´æ•°é¦¬èº« "1", "2", "3"
        int_match = _re.match(r'^(\d+)$', text)
        if int_match:
            return round(int(int_match.group(1)) * 0.6, 2)
        
        return 0.0

    def _get_horse_history(self, horse_id: str, current_weight: float,
                          target_distance: int, target_course: str) -> List[Dict]:
        """å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
        
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")
            
            table = soup.find("table", class_="db_h_race_results")
            if not table:
                return []
            
            headers = [th.text.strip() for th in table.find_all("th")]
            
            def find_col(keywords):
                for kw in keywords:
                    for i, h in enumerate(headers):
                        if kw in h:
                            return i
                return -1
            
            idx_date = find_col(["æ—¥ä»˜"])
            idx_course = find_col(["é–‹å‚¬"])
            idx_race = find_col(["ãƒ¬ãƒ¼ã‚¹å"])
            idx_dist = find_col(["è·é›¢"])
            idx_chakujun = find_col(["ç€é †"])
            idx_weight = find_col(["æ–¤é‡"])
            idx_chakusa = find_col(["ç€å·®"])
            idx_3f = find_col(["ä¸Šã‚Š"])
            idx_corner = find_col(["é€šéé †ä½", "é€šé", "ã‚³ãƒ¼ãƒŠãƒ¼"])  # é€šéé †ä½ï¼ˆ4è§’ãªã©ï¼‰
            idx_tosu = find_col(["é ­æ•°", "å‡ºèµ°é ­æ•°"])  # é ­æ•°
            
            if idx_date == -1: idx_date = 0
            if idx_course == -1: idx_course = 1
            if idx_race == -1: idx_race = 4
            if idx_dist == -1: idx_dist = 14
            if idx_chakujun == -1: idx_chakujun = 11
            if idx_weight == -1: idx_weight = 13
            if idx_chakusa == -1: idx_chakusa = 18
            if idx_3f == -1: idx_3f = 20
            # é€šéé †ä½ã¨é ­æ•°ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè¦‹ã¤ã‹ã‚‰ãªãã¦ã‚‚-1ã®ã¾ã¾ï¼‰
            
            rows = table.find_all("tr")[1:8]  # ä¸­æ­¢ãƒ»é™¤å¤–ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—7è¡Œå–å¾—â†’å®Ÿè³ª5èµ°ç¢ºä¿
            history = []
            
            for idx, row in enumerate(rows):
                cols = row.find_all("td")
                if len(cols) < max(idx_date, idx_course, idx_race, idx_dist, 
                                  idx_chakujun, idx_weight, idx_chakusa) + 1:
                    continue
                
                try:
                    date_raw = cols[idx_date].text.strip()
                    # netkeibaã®æ—¥ä»˜ã¯ "2025å¹´11æœˆ03æ—¥" å½¢å¼ãªã®ã§ "2025/11/03" ã«æ­£è¦åŒ–
                    import re as _re
                    _date_match = _re.search(r'(\d{4})[å¹´/](\d{1,2})[æœˆ/](\d{1,2})', date_raw)
                    if _date_match:
                        date = f"{_date_match.group(1)}/{int(_date_match.group(2)):02d}/{int(_date_match.group(3)):02d}"
                    else:
                        date = date_raw  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    course_raw = cols[idx_course].text.strip()
                    # netkeibaã®ã€Œé–‹å‚¬ã€åˆ—ã¯ "1æ±äº¬1" "2ä¸­å±±3" ã®ã‚ˆã†ãªå½¢å¼ãªã®ã§ç«¶é¦¬å ´åã ã‘æŠ½å‡º
                    _known_courses = ["æœ­å¹Œ", "å‡½é¤¨", "ç¦å³¶", "æ–°æ½Ÿ", "æ±äº¬", "ä¸­å±±", "ä¸­äº¬", "äº¬éƒ½", "é˜ªç¥", "å°å€‰",
                                      "å¤§äº•", "å·å´", "èˆ¹æ©‹", "æµ¦å’Œ", "é–€åˆ¥", "ç››å²¡", "æ°´æ²¢", "é‡‘æ²¢", "ç¬ æ¾", "åå¤å±‹", "åœ’ç”°", "å§«è·¯", "é«˜çŸ¥", "ä½è³€"]
                    course_name = course_raw  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    for _c in _known_courses:
                        if _c in course_raw:
                            course_name = _c
                            break
                    
                    race_cell = cols[idx_race]
                    race_link = race_cell.find("a")
                    race_name = race_link.get_text(strip=True) if race_link else race_cell.get_text(strip=True)
                    
                    race_id = ""
                    if race_link:
                        href = race_link.get("href", "")
                        match = re.search(r"race/(\d{12})", href)
                        if match:
                            race_id = match.group(1)
                    
                    dist_text = cols[idx_dist].text.strip()
                    
                    # ãƒˆãƒ©ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‚’è·é›¢åˆ—ã‹ã‚‰ç›´æ¥ãƒ‘ãƒ¼ã‚¹ï¼ˆä¾‹: "èŠ1600", "ãƒ€1200", "éšœ3000"ï¼‰
                    track_type_match = re.match(r"^(èŠ|ãƒ€|ãƒ€ãƒ¼ãƒˆ|éšœ)", dist_text)
                    if track_type_match:
                        track_prefix = track_type_match.group(1)
                        if track_prefix == "èŠ":
                            race_track_type = "èŠ"
                        elif track_prefix in ["ãƒ€", "ãƒ€ãƒ¼ãƒˆ"]:
                            race_track_type = "ãƒ€ãƒ¼ãƒˆ"
                        elif track_prefix == "éšœ":
                            race_track_type = "éšœå®³"
                        else:
                            race_track_type = "ä¸æ˜"
                    else:
                        race_track_type = "ä¸æ˜"
                    
                    dist_match = re.search(r"(\d+)", dist_text)
                    distance = int(dist_match.group(1)) if dist_match else 0
                    
                    chakujun_text = cols[idx_chakujun].text.strip()
                    # ç«¶èµ°ä¸­æ­¢ãƒ»é™¤å¤–ãƒ»å–æ¶ˆã¯å°‚ç”¨ã‚³ãƒ¼ãƒ‰ã§ç®¡ç†
                    if "ä¸­æ­¢" in chakujun_text:
                        chakujun = 0   # ç«¶èµ°ä¸­æ­¢
                    elif "é™¤å¤–" in chakujun_text:
                        chakujun = 0   # é™¤å¤–ï¼ˆå‡ºèµ°å–æ¶ˆå«ã‚€ï¼‰
                    elif "å–æ¶ˆ" in chakujun_text or "å–ã‚Šæ¶ˆ" in chakujun_text:
                        chakujun = 0   # å–æ¶ˆ
                    else:
                        chakujun_match = re.search(r"(\d+)", chakujun_text)
                        chakujun = int(chakujun_match.group(1)) if chakujun_match else 99

                    # ä¸­æ­¢ãƒ»é™¤å¤–ãƒ»å–æ¶ˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå±¥æ­´ã«å«ã‚ãªã„ï¼‰
                    if chakujun == 0:
                        logger.info(f"    [{idx+1}èµ°å‰] {race_name[:15]:15s}: ç€é †='{chakujun_text}' â†’ ã‚¹ã‚­ãƒƒãƒ—")
                        continue

                    # ç€å·®åˆ—: 1ç€ã‹ã‚‰ã®ã‚¿ã‚¤ãƒ å·®ï¼ˆç§’æ•°ï¼‰ã®ã¿ä½¿ç”¨ã€‚å¤‰æ›ä¸å¯æ™‚ã¯0.0ã§ãƒ­ã‚°å‡ºåŠ›
                    chakusa_text = cols[idx_chakusa].text.strip() if idx_chakusa < len(cols) else ""
                    if chakujun == 1:
                        goal_time_diff = 0.0
                    else:
                        try:
                            goal_time_diff = float(chakusa_text)
                        except Exception:
                            goal_time_diff = 0.0
                            logger.info(f"    [ç€å·®] {idx+1}èµ°å‰ {race_name[:12]:12s}: "
                                        f"col={idx_chakusa} raw='{chakusa_text}' â†’ æ•°å€¤å¤‰æ›ä¸å¯ âš ï¸å¤§æ•—åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—")
                    
                    weight_text = cols[idx_weight].text.strip()
                    try:
                        weight = float(weight_text)
                    except:
                        weight = current_weight
                    
                    time_3f_text = cols[idx_3f].text.strip() if idx_3f < len(cols) else ""
                    try:
                        last_3f = float(time_3f_text)
                    except:
                        last_3f = 0.0
                    
                    # é€šéé †ä½ã‚’å–å¾—ï¼ˆ4è§’é †ä½ãªã©ï¼‰
                    corner_pos = 0
                    if idx_corner != -1 and idx_corner < len(cols):
                        corner_text = cols[idx_corner].text.strip()
                        # "1-1-1-1"ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰æœ€å¾Œã®æ•°å­—ï¼ˆ4è§’ï¼‰ã‚’å–å¾—
                        positions = re.findall(r'\d+', corner_text)
                        if positions:
                            corner_pos = int(positions[-1])  # æœ€å¾Œã®ä½ç½®ï¼ˆ4è§’ï¼‰
                    
                    # é ­æ•°ã‚’å–å¾—
                    field_size = 16  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                    if idx_tosu != -1 and idx_tosu < len(cols):
                        tosu_text = cols[idx_tosu].text.strip()
                        tosu_match = re.search(r'(\d+)', tosu_text)
                        if tosu_match:
                            field_size = int(tosu_match.group(1))
                    
                    race_stats = {}
                    if race_id and last_3f > 0:
                        time.sleep(0.3)
                        race_stats = self._get_race_last_3f_stats(race_id)
                    elif not race_id and self.debug_mode:
                        logger.debug(f"    race_idæœªå–å¾— â†’ goal_time_diff=0.0ï¼ˆé€£ç¶šå¤§æ•—åˆ¤å®šä¸å¯ï¼‰")
                    
                    # ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‹ã‚‰å¾ŒåŠ4Fã‚’è¨ˆç®—
                    lap_times = race_stats.get('lap_times', [])
                    late_4f = self._calculate_late_4f_from_laps(lap_times) if lap_times else 0.0
                    
                    # é¦¬å ´çŠ¶æ…‹ã‚’å–å¾—
                    baba = race_stats.get('baba', 'è‰¯')
                    
                    # goal_time_diffã¯é¦¬ã®æˆ¦ç¸¾ãƒšãƒ¼ã‚¸ã®ã€Œç€å·®ã€åˆ—ï¼ˆ1ç€åŸºæº–ãƒ»ç§’æ•°ï¼‰ã‚’ãã®ã¾ã¾ä½¿ç”¨
                    
                    history.append({
                        'date': date,
                        'race_date': date,  # v6ç”¨: YYYY/MM/DDå½¢å¼
                        'course': course_name,
                        'dist': distance,
                        'track_type': race_track_type,
                        'baba': baba,  # é¦¬å ´çŠ¶æ…‹
                        'chakujun': chakujun,
                        'chakusa': chakusa_text,
                        'goal_time_diff': goal_time_diff,  # v6ç”¨: é€£ç¶šå¤§æ•—ãƒšãƒŠãƒ«ãƒ†ã‚£
                        'weight': weight,
                        'last_3f': last_3f,
                        'late_4f': late_4f,  # å¾ŒåŠ4Fï¼ˆãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‹ã‚‰è¨ˆç®—ï¼‰
                        'race_name': race_name,
                        'race_avg_last_3f': race_stats.get('avg_last_3f', 0.0),
                        'race_min_last_3f': race_stats.get('min_last_3f', 0.0),
                        'race_max_last_3f': race_stats.get('max_last_3f', 0.0),
                        'race_std_last_3f': race_stats.get('std_last_3f', 0.0),
                        'all_horses_results': race_stats.get('all_horses_results', []),
                        'corner_pos': corner_pos,  # v6ç”¨: é€šéé †ä½ï¼ˆ4è§’ï¼‰
                        'position_4c': corner_pos,  # v6ç”¨: æ–°é¦¬æˆ¦2æˆ¦ç›®ãƒ–ãƒ¼ã‚¹ãƒˆ
                        'field_size': field_size,
                    })
                    
                except Exception as e:
                    continue
            
            return history
            
        except Exception as e:
            logger.error(f"æˆ¦ç¸¾å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _get_course_name(self, race_id: str) -> str:
        venues = {
            "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ",
            "05": "æ±äº¬", "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½",
            "09": "é˜ªç¥", "10": "å°å€‰"
        }
        code = race_id[4:6] if len(race_id) >= 6 else ""
        return venues.get(code, "ä¸æ˜")

    def _parse_shutuba(self, soup: BeautifulSoup) -> List[Dict]:
        horse_data = []
        
        table = None
        patterns = [
            ("table", {"class_": "Shutuba_Table"}),
            ("table", {"class_": re.compile(r"shutuba", re.I)}),
            ("table", {"class_": "RaceList"}),
            ("table", {"class_": re.compile(r"race.*list", re.I)}),
        ]
        
        for tag, attrs in patterns:
            table = soup.find(tag, attrs)
            if table:
                break
        
        if not table:
            for t in soup.find_all("table"):
                if t.find("th") and ("é¦¬å" in str(t) or "horse" in str(t).lower()):
                    table = t
                    break
        
        if not table:
            self._debug_print("âŒ å‡ºé¦¬è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return []

        rows = table.find_all("tr")
        start = 1 if rows and rows[0].find("th") else 0
        
        for row_idx, row in enumerate(rows[start:], 1):
            cols = row.find_all(["td", "th"])
            if len(cols) < 5:
                continue
            
            try:
                info = self._extract_horse_info(cols, row, row_idx)
                if info and info.get("é¦¬å") and info.get("horse_id"):
                    horse_data.append(info)
            except Exception as e:
                if self.debug_mode:
                    self._debug_print(f"  è¡Œ{row_idx}ã®è§£æå¤±æ•—: {e}", "WARNING")
                continue
        
        return horse_data

    def _extract_horse_info(self, cols, row, row_idx: int) -> Optional[Dict]:
        info = {
            "æ ": "", "é¦¬ç•ª": "", "é¦¬å": "", "æ€§é½¢": "",
            "æ–¤é‡": 54.0, "é¨æ‰‹": "", "ã‚ªãƒƒã‚º": 1.0, "horse_id": ""
        }
        
        for col in cols:
            if not info["é¦¬å"]:
                link = col.find("a", href=re.compile(r"/horse/\d+"))
                if link:
                    info["é¦¬å"] = link.get_text(strip=True)
                    href = link.get("href", "")
                    match = re.search(r"/horse/(\d{10,})", href)
                    if match:
                        info["horse_id"] = match.group(1)
        
        for col in cols:
            if not info["é¨æ‰‹"]:
                jockey_link = col.find("a", href=re.compile(r"/jockey/"))
                if jockey_link:
                    info["é¨æ‰‹"] = jockey_link.get_text(strip=True)
        
        for idx in range(min(3, len(cols))):
            col = cols[idx]
            text = col.get_text(strip=True)
            
            if not info["æ "] and len(text) == 1 and text.isdigit() and 1 <= int(text) <= 8:
                info["æ "] = text
            elif not info["é¦¬ç•ª"] and len(text) <= 2 and text.isdigit() and 1 <= int(text) <= 18:
                info["é¦¬ç•ª"] = text
        
        for col in cols:
            text = col.get_text(strip=True)
            
            if not info["æ€§é½¢"]:
                import unicodedata as _ud

                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ç‹¬ç«‹ã—ãŸtdã«ã€Œç‰3ã€ãªã©ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆ
                _norm = _ud.normalize('NFKC', text).replace(' ', '').replace('\u3000', '')
                if re.match(r"^[ç‰¡ç‰ã‚»]\d{1,2}$", _norm):
                    info["æ€§é½¢"] = _norm

                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: é¦¬åã¨åŒã˜tdã«ã€Œã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¬ãƒ¼ãƒ«ç‰3ã€ã®ã‚ˆã†ã«å«ã¾ã‚Œã‚‹å ´åˆ
                if not info["æ€§é½¢"]:
                    m = re.search(r'([ç‰¡ç‰ã‚»])(\d{1,2})', _norm)
                    if m:
                        info["æ€§é½¢"] = m.group(1) + m.group(2)

                # ãƒ‘ã‚¿ãƒ¼ãƒ³3: spanãªã©ã®ã‚µãƒ–è¦ç´ ã«æ€§é½¢ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆ
                if not info["æ€§é½¢"]:
                    for span in col.find_all(['span', 'td', 'div']):
                        _s = _ud.normalize('NFKC', span.get_text(strip=True)).replace(' ', '')
                        if re.match(r"^[ç‰¡ç‰ã‚»]\d{1,2}$", _s):
                            info["æ€§é½¢"] = _s
                            break
            
            if info["æ–¤é‡"] == 54.0:
                weight_match = re.match(r"^(\d{2}\.\d)$", text)
                if weight_match:
                    val = float(weight_match.group(1))
                    if 48.0 <= val <= 60.0:
                        info["æ–¤é‡"] = val
                        continue
                
                weight_match = re.match(r"^(\d{2})$", text)
                if weight_match:
                    val = float(weight_match.group(1))
                    if 48.0 <= val <= 60.0:
                        info["æ–¤é‡"] = val
                        continue
        
        if not info["é¦¬å"] or not info["horse_id"]:
            return None
        
        if not info["æ "]:
            info["æ "] = str(row_idx)
        if not info["é¦¬ç•ª"]:
            info["é¦¬ç•ª"] = str(row_idx)
        
        return info

    def _extract_lap_times(self, soup: BeautifulSoup) -> List[float]:
        """
        ãƒ¬ãƒ¼ã‚¹çµæœãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ï¼ˆãƒãƒ­ãƒ³ã‚¿ã‚¤ãƒ ï¼‰ã‚’æŠ½å‡º
        
        Returns:
            List[float]: å„ãƒãƒ­ãƒ³ï¼ˆ200mï¼‰ã®ã‚¿ã‚¤ãƒ ï¼ˆç§’ï¼‰ã®ãƒªã‚¹ãƒˆ
                        ä¾‹: [12.3, 11.2, 11.5, 11.8, 12.0, 11.9, 11.7, 11.4]
        """
        lap_times = []
        
        try:
            # æ–¹æ³•1: "ãƒ©ãƒƒãƒ—"ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€è¦ç´ ã‚’æ¢ã™
            # netkeibaã§ã¯ã€Œãƒ©ãƒƒãƒ—ã€ãƒ©ãƒ™ãƒ«ã®å¾Œã«ãƒãƒ­ãƒ³ã‚¿ã‚¤ãƒ ãŒä¸¦ã¶
            for elem in soup.find_all(text=lambda t: t and "ãƒ©ãƒƒãƒ—" in t):
                parent = elem.parent
                if parent:
                    # æ¬¡ã®å…„å¼Ÿè¦ç´ ã‚„è¦ªè¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‚’æŠ½å‡º
                    next_elem = parent.next_sibling
                    if next_elem:
                        lap_text = next_elem.get_text(strip=True) if hasattr(next_elem, 'get_text') else str(next_elem)
                    else:
                        lap_text = parent.get_text(strip=True)
                    
                    # "ãƒ©ãƒƒãƒ—"ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ­ãƒ³ã‚¿ã‚¤ãƒ ã‚’æŠ½å‡º
                    # å½¢å¼: "12.3-11.2-11.5-11.8" ã¾ãŸã¯ "12.3 - 11.2 - 11.5"
                    lap_text = lap_text.replace("ãƒ©ãƒƒãƒ—", "").strip()
                    
                    # ãƒã‚¤ãƒ•ãƒ³ã¾ãŸã¯ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã‚‰ã‚ŒãŸæ•°å€¤ã‚’æŠ½å‡º
                    times = re.findall(r'\d+\.\d+', lap_text)
                    if times:
                        lap_times = [float(t) for t in times]
                        if self.debug_mode:
                            logger.debug(f"  ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ å–å¾—: {len(lap_times)}ãƒãƒ­ãƒ³")
                        break
            
            # æ–¹æ³•2: ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ è¡Œã‚’æ¢ã™
            if not lap_times:
                for table in soup.find_all("table"):
                    for row in table.find_all("tr"):
                        row_text = row.get_text(strip=True)
                        if "ãƒ©ãƒƒãƒ—" in row_text:
                            # ã“ã®è¡Œã‹ã‚‰ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‚’æŠ½å‡º
                            times = re.findall(r'\d+\.\d+', row_text)
                            if len(times) >= 4:  # å°‘ãªãã¨ã‚‚4ãƒãƒ­ãƒ³ä»¥ä¸Š
                                lap_times = [float(t) for t in times]
                                if self.debug_mode:
                                    logger.debug(f"  ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ å–å¾—ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰: {len(lap_times)}ãƒãƒ­ãƒ³")
                                break
                    if lap_times:
                        break
            
            # æ–¹æ³•3: divå†…ã®ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ æƒ…å ±
            if not lap_times:
                for div in soup.find_all("div"):
                    div_text = div.get_text(strip=True)
                    if "ãƒ©ãƒƒãƒ—" in div_text and "-" in div_text:
                        times = re.findall(r'\d+\.\d+', div_text)
                        if len(times) >= 4:
                            lap_times = [float(t) for t in times]
                            if self.debug_mode:
                                logger.debug(f"  ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ å–å¾—ï¼ˆdivï¼‰: {len(lap_times)}ãƒãƒ­ãƒ³")
                            break
        
        except Exception as e:
            if self.debug_mode:
                logger.debug(f"  ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ å–å¾—å¤±æ•—: {e}")
        
        return lap_times
    
    def _calculate_late_4f_from_laps(self, lap_times: List[float]) -> float:
        """
        ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‹ã‚‰å¾ŒåŠ4Fï¼ˆå¾ŒåŠ4ãƒãƒ­ãƒ³ = 800mï¼‰ã‚’è¨ˆç®—
        
        Args:
            lap_times: ãƒãƒ­ãƒ³ã‚¿ã‚¤ãƒ ï¼ˆ200mÃ—nãƒãƒ­ãƒ³ï¼‰ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            float: å¾ŒåŠ4Fã®ã‚¿ã‚¤ãƒ ï¼ˆç§’ï¼‰ã€‚è¨ˆç®—ã§ããªã„å ´åˆã¯0.0
        """
        if not lap_times or len(lap_times) < 4:
            return 0.0
        
        # å¾ŒåŠ4ãƒãƒ­ãƒ³ = æœ€å¾Œã®4ã¤ã®ãƒãƒ­ãƒ³ã‚¿ã‚¤ãƒ ã‚’åˆè¨ˆ
        late_4f = sum(lap_times[-4:])
        return round(late_4f, 1)
    
    def _get_race_last_3f_stats(self, race_id: str) -> Dict:
        """éå»ãƒ¬ãƒ¼ã‚¹ã®ä¸ŠãŒã‚Š3Fçµ±è¨ˆã¨å‡ºèµ°é¦¬å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ãƒ»é¦¬å ´çŠ¶æ…‹å«ã‚€ï¼‰"""
        url = f"https://db.netkeiba.com/race/{race_id}/"
        
        try:
            response = self.session.get(url, timeout=15)
            
            if response.status_code == 404:
                return {}
            
            response.raise_for_status()
            response.encoding = 'EUC-JP'
            soup = BeautifulSoup(response.content, "html.parser", from_encoding='EUC-JP')
            
            # ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã‚’å–å¾—
            lap_times = self._extract_lap_times(soup)
            
            # é¦¬å ´çŠ¶æ…‹ã‚’å–å¾—
            baba = self._get_baba(soup)
            
            table = soup.find("table", class_="race_table_01")
            if not table:
                return {}
            
            headers = table.find_all("th")
            
            # å„åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            last_3f_idx = -1
            chakujun_idx = -1
            time_idx = -1  # ã‚´ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ åˆ—

            for i, th in enumerate(headers):
                text = th.get_text(strip=True)
                if any(kw in text for kw in ["ä¸Šã‚Š", "ä¸ŠãŒã‚Š", "3F"]):
                    last_3f_idx = i
                elif "ç€é †" in text or text == "ç€":
                    chakujun_idx = i
                elif text == "ã‚¿ã‚¤ãƒ " or text == "èµ°ç ´ã‚¿ã‚¤ãƒ ":
                    time_idx = i

            if last_3f_idx == -1:
                last_3f_idx = len(headers) - 2
            if chakujun_idx == -1:
                chakujun_idx = 0
            if time_idx == -1:
                time_idx = 7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½ç½®

            def parse_time_to_sec(t):
                """'1:12.3' ã¾ãŸã¯ '72.3' ã‚’ç§’æ•°(float)ã«å¤‰æ›"""
                t = t.strip()
                if ':' in t:
                    parts = t.split(':')
                    try:
                        return int(parts[0]) * 60 + float(parts[1])
                    except:
                        return None
                try:
                    return float(t)
                except:
                    return None

            values = []
            all_horses_results = []
            first_place_time = None  # 1ç€ã®ã‚´ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ ï¼ˆç§’ï¼‰

            for row in table.find_all("tr")[1:]:
                tds = row.find_all("td")
                if len(tds) <= max(last_3f_idx, chakujun_idx, time_idx):
                    continue
                try:
                    chakujun_text = tds[chakujun_idx].get_text(strip=True)
                    chakujun_match = re.search(r'(\d+)', chakujun_text)
                    if not chakujun_match:
                        continue
                    chakujun = int(chakujun_match.group(1))

                    time_text = tds[time_idx].get_text(strip=True)
                    goal_sec = parse_time_to_sec(time_text)

                    last_3f_text = re.sub(r"[()ï¼ˆï¼‰]", "", tds[last_3f_idx].get_text(strip=True))
                    try:
                        last_3f = float(last_3f_text)
                    except:
                        last_3f = 0.0

                    if chakujun == 1 and goal_sec:
                        first_place_time = goal_sec

                    all_horses_results.append({
                        'chakujun': chakujun,
                        'last_3f': last_3f,
                        'goal_sec': goal_sec,   # å¾Œã§goal_time_diffã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ä¿æŒ
                        'goal_time_diff': 0.0   # å¾Œã§ä¸Šæ›¸ã
                    })

                    if last_3f > 30 and last_3f < 50:
                        values.append(last_3f)
                except:
                    continue

            # 1ç€ã‚¿ã‚¤ãƒ ãŒå–ã‚ŒãŸå ´åˆã€å…¨é¦¬ã®goal_time_diffã‚’è¨ˆç®—
            if first_place_time:
                for h in all_horses_results:
                    if h['chakujun'] == 1:
                        h['goal_time_diff'] = 0.0
                    elif h['goal_sec']:
                        h['goal_time_diff'] = round(h['goal_sec'] - first_place_time, 3)
                    else:
                        h['goal_time_diff'] = 0.0
            
            if not values:
                return {}
            
            result = {
                'avg_last_3f': round(statistics.mean(values), 2),
                'min_last_3f': round(min(values), 2),
                'max_last_3f': round(max(values), 2),
                'median_last_3f': round(statistics.median(values), 2),
                'std_last_3f': round(statistics.stdev(values), 2) if len(values) > 1 else 0.0,
                'count': len(values),
                'all_horses_results': all_horses_results,  # å…¨é¦¬ã®ãƒ‡ãƒ¼ã‚¿
                'lap_times': lap_times,  # ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ï¼ˆ200mã”ã¨ï¼‰
                'baba': baba  # é¦¬å ´çŠ¶æ…‹
            }
            
            return result
            
        except Exception as e:
            return {}

    def _get_race_name(self, soup: BeautifulSoup) -> str:
        elem = soup.find("div", class_="RaceName")
        if elem:
            name = elem.get_text(strip=True)
            name = re.sub(r"å‡ºé¦¬è¡¨.*", "", name).strip()
            if name:
                return name
        
        for h1 in soup.find_all("h1"):
            name = h1.get_text(strip=True)
            if name and len(name) > 2:
                return re.sub(r"å‡ºé¦¬è¡¨.*", "", name).strip()
        
        return "ãƒ¬ãƒ¼ã‚¹"

    def _get_race_distance(self, soup: BeautifulSoup) -> int:
        elem = soup.find("div", class_="RaceData01")
        if elem:
            match = re.search(r"[èŠãƒ€éšœ](\d+)m", elem.text)
            if match:
                return int(match.group(1))
        return 1600

    def _get_track_type(self, soup: BeautifulSoup) -> str:
        # â‘  ãƒ¬ãƒ¼ã‚¹åã«ã€Œéšœå®³ã€ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°æœ€å„ªå…ˆã§éšœå®³åˆ¤å®š
        race_name_elem = soup.find("div", class_="RaceName")
        race_name_text = race_name_elem.get_text(strip=True) if race_name_elem else ""
        if "éšœå®³" in race_name_text or "éšœ" in race_name_text:
            return "éšœå®³"

        # â‘¡ RaceData01 ã®ãƒ†ã‚­ã‚¹ãƒˆã§åˆ¤å®šï¼ˆéšœå®³ã‚’èŠã‚ˆã‚Šå…ˆã«ãƒã‚§ãƒƒã‚¯ï¼‰
        elem = soup.find("div", class_="RaceData01")
        if elem:
            text = elem.text
            # éšœå®³ã¯ã€ŒèŠã€ã€Œãƒ€ã€ã‚‚å«ã‚€è¤‡åˆã‚³ãƒ¼ã‚¹ãªã®ã§æœ€åˆã«åˆ¤å®š
            if "éšœ" in text:
                return "éšœå®³"
            elif "èŠ" in text:
                return "èŠ"
            elif "ãƒ€" in text or "ãƒ€ãƒ¼ãƒˆ" in text:
                return "ãƒ€ãƒ¼ãƒˆ"
        return "ä¸æ˜"
    
    def _get_baba(self, soup: BeautifulSoup) -> str:
        """
        é¦¬å ´çŠ¶æ…‹ã‚’å–å¾—
        
        Returns:
            str: 'è‰¯', 'ç¨é‡', 'é‡', 'ä¸è‰¯' ã®ã„ãšã‚Œã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'è‰¯'ï¼‰
        """
        elem = soup.find("div", class_="RaceData01")
        if elem:
            text = elem.get_text(strip=True)
            # é¦¬å ´çŠ¶æ…‹ã®é †åºã«æ³¨æ„ï¼ˆã€Œç¨é‡ã€ã‚’å…ˆã«ãƒã‚§ãƒƒã‚¯ï¼‰
            if "ä¸è‰¯" in text:
                return "ä¸è‰¯"
            elif "é‡" in text and "ç¨" not in text:
                return "é‡"
            elif "ç¨é‡" in text or "ç¨" in text:
                return "ç¨é‡"
            elif "è‰¯" in text:
                return "è‰¯"
        return "è‰¯"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ


if __name__ == "__main__":
    print("âœ… NetkeibaRaceScraper v5ï¼ˆenhanced_scorer_v7å¯¾å¿œãƒ»éå»5èµ°è©•ä¾¡ç‰ˆï¼‰loaded")
