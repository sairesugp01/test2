"""
ç«¶é¦¬äºˆæƒ³AI - scraper_v3_fixed.pyï¼ˆv8çµ±åˆç‰ˆï¼‰
æœ€çµ‚æ›´æ–°: 2026å¹´2æœˆ9æ—¥

ä¸»ãªæ©Ÿèƒ½:
1. v4ã®åŸºæœ¬æ©Ÿèƒ½ã‚’ç¶™æ‰¿
2. v8çµ±åˆæ©Ÿèƒ½ã‚’è¿½åŠ :
   - è„šè³ªåˆ†æï¼ˆé€šéé †ä½ã‹ã‚‰è‡ªå‹•åˆ¤å®šï¼‰
   - ãƒšãƒ¼ã‚¹äºˆæ¸¬ï¼ˆå‡ºèµ°é ­æ•°ãƒ»é€ƒã’é¦¬ã®è³ªã‚’è€ƒæ…®ï¼‰
   - è„šè³ªÃ—å±•é–‹Ã—ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®é©åˆåº¦ãƒœãƒ¼ãƒŠã‚¹
3. ã‚¹ã‚³ã‚¢å†…è¨³ã®è¦‹ã‚„ã™ã„è¡¨ç¤ºï¼ˆformat_score_breakdownä½¿ç”¨ï¼‰
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import logging
import statistics
from typing import List, Dict, Optional, Tuple
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from enhanced_scorer_v5 import EnhancedRaceScorer
except ImportError as e:
    logger.error(f"Import error: {e}")
    raise ImportError("enhanced_scorer_v5.py ãŒå¿…è¦ã§ã™")


class NetkeibaRaceScraper:
    """netkeibaã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v4ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
    
    def __init__(self, scraping_delay: float = 1.0, debug_mode: bool = False):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.scorer = EnhancedRaceScorer(debug_mode=debug_mode)
        self.scraping_delay = scraping_delay
        self.debug_mode = debug_mode
        self.debug_logs = []
        self.skip_new_horse = True  # æ–°é¦¬æˆ¦ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        self.cache_hits = 0
        self.api_calls = 0
        self.progress_callback = None  # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

    def _extract_running_style_from_history(self, history: List[Dict]) -> Optional[Dict]:
        """
        éå»æˆ¦ç¸¾ã‹ã‚‰è„šè³ªã‚’åˆ¤å®š
        
        Args:
            history: éå»æˆ¦ç¸¾ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            {'style': 'é€ƒã’', 'confidence': 0.85, ...} or None
        """
        if not history:
            return None
        
        # é€šéé †ä½ã‚’æŠ½å‡ºï¼ˆã‚³ãƒ¼ãƒŠãƒ¼é †ä½ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
        passing_positions = []
        field_sizes = []
        
        for race in history[:5]:  # ç›´è¿‘5èµ°ã‚’ä½¿ç”¨
            # é€šéé †ä½ï¼ˆ4è§’é †ä½ãªã©ï¼‰ã‚’å–å¾—
            corner_pos = race.get('corner_pos', None)
            if corner_pos and corner_pos > 0:
                passing_positions.append(corner_pos)
                field_size = race.get('field_size', 16)
                field_sizes.append(field_size)
        
        if not passing_positions:
            return None
        
        # EnhancedRaceScorerã®è„šè³ªåˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨
        return self.scorer.style_analyzer.classify_running_style(
            passing_positions, field_sizes if field_sizes else None
        )
    
    def _predict_race_pace(self, horses_running_styles: List[Dict], field_size: int) -> Dict:
        """
        ãƒ¬ãƒ¼ã‚¹å…¨ä½“ã®ãƒšãƒ¼ã‚¹ã‚’äºˆæ¸¬
        
        Args:
            horses_running_styles: å„é¦¬ã®è„šè³ªæƒ…å ±ãƒªã‚¹ãƒˆ
            field_size: å‡ºèµ°é ­æ•°
            
        Returns:
            {'pace': 'ãƒã‚¤'/'ãƒŸãƒ‰ãƒ«'/'ã‚¹ãƒ­ãƒ¼', ...}
        """
        if not horses_running_styles:
            return {'pace': 'ãƒŸãƒ‰ãƒ«', 'front_runners': 0, 'closers': 0}
        
        # EnhancedRaceScorerã®ãƒšãƒ¼ã‚¹äºˆæ¸¬æ©Ÿèƒ½ã‚’ä½¿ç”¨
        return self.scorer.style_analyzer.predict_race_pace(
            horses_running_styles, field_size
        )

    def _init_session_state(self):
        """Streamlitã®session_stateã‚’åˆæœŸåŒ–"""
        try:
            import streamlit as st
            if 'horse_cache_by_name' not in st.session_state:
                st.session_state.horse_cache_by_name = {}
            if 'race_cache' not in st.session_state:
                st.session_state.race_cache = {}
            return True
        except ImportError:
            return False

    def _get_cache_key_by_name(self, horse_name: str) -> str:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼"""
        normalized = re.sub(r'\s+', '', horse_name).lower()
        return normalized

    def _get_from_cache(self, horse_name: str) -> Optional[List[Dict]]:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        if not self._init_session_state():
            return None
        
        try:
            import streamlit as st
            cache_key = self._get_cache_key_by_name(horse_name)
            if cache_key in st.session_state.horse_cache_by_name:
                self.cache_hits += 1
                self._debug_print(f"  ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ(é¦¬å): {horse_name}", "DEBUG")
                return st.session_state.horse_cache_by_name[cache_key]
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None

    def _save_to_cache(self, horse_name: str, data: List[Dict]):
        """é¦¬åãƒ™ãƒ¼ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
        if not self._init_session_state():
            return
        
        try:
            import streamlit as st
            cache_key = self._get_cache_key_by_name(horse_name)
            st.session_state.horse_cache_by_name[cache_key] = data
            self._debug_print(f"  ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜(é¦¬å): {horse_name}", "DEBUG")
        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _check_race_cache(self, race_name: str, horse_names: List[str]) -> Optional[pd.DataFrame]:
        """åŒã˜ãƒ¬ãƒ¼ã‚¹åãƒ»åŒã˜é¦¬ã®çµ„ã¿åˆã‚ã›ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self._init_session_state():
            return None
        
        try:
            import streamlit as st
            
            race_key = re.sub(r'\s+', '', race_name).lower()
            horse_set = set(self._get_cache_key_by_name(h) for h in horse_names)
            
            for cached_race, cached_df in st.session_state.race_cache.items():
                if cached_race == race_key:
                    cached_horses = set(self._get_cache_key_by_name(h) for h in cached_df['é¦¬å'].tolist())
                    if horse_set == cached_horses:
                        self._debug_print(f"ğŸ“¦ ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {race_name}", "INFO")
                        return cached_df
            
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None

    def _save_race_cache(self, race_name: str, df: pd.DataFrame):
        """ãƒ¬ãƒ¼ã‚¹çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        if not self._init_session_state():
            return
        
        try:
            import streamlit as st
            race_key = re.sub(r'\s+', '', race_name).lower()
            st.session_state.race_cache[race_key] = df.copy()
            self._debug_print(f"ğŸ’¾ ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {race_name}", "INFO")
        except Exception as e:
            logger.warning(f"ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def get_cache_stats(self) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—"""
        try:
            import streamlit as st
            name_cache_size = len(st.session_state.get('horse_cache_by_name', {}))
            race_cache_size = len(st.session_state.get('race_cache', {}))
        except:
            name_cache_size = 0
            race_cache_size = 0
        
        total = self.cache_hits + self.api_calls
        return {
            'name_cache_size': name_cache_size,
            'race_cache_size': race_cache_size,
            'cache_hits': self.cache_hits,
            'api_calls': self.api_calls,
            'hit_rate': (self.cache_hits / total * 100) if total > 0 else 0
        }

    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        try:
            import streamlit as st
            st.session_state.horse_cache_by_name = {}
            st.session_state.race_cache = {}
            self.cache_hits = 0
            self.api_calls = 0
            logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def _debug_print(self, message: str, level: str = "INFO"):
        """ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        
        if self.debug_mode:
            print(log_entry)
        
        self.debug_logs.append(log_entry)
        if level == "ERROR":
            logger.error(message)
        elif level == "WARNING":
            logger.warning(message)
        else:
            logger.info(message)

    def check_if_new_horse_race(self, soup: BeautifulSoup, race_name: str = "") -> Tuple[bool, str]:
        """æ–°é¦¬æˆ¦ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆãƒ¬ãƒ¼ã‚¹åã®ã¿ã§åˆ¤æ–­ï¼‰"""
        # ãƒ¬ãƒ¼ã‚¹åã«ã€Œæ–°é¦¬ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—
        # ã€Œ2æ­³æ–°é¦¬ã€ã€Œ3æ­³æ–°é¦¬ã€ãªã©
        if 'æ–°é¦¬' in race_name:
            return True, f"ãƒ¬ãƒ¼ã‚¹åã«'æ–°é¦¬'ã‚’æ¤œå‡º: {race_name}"
        
        # ã€Œæœªå‹åˆ©ã€ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„
        return False, ""

    def get_race_data(self, race_id: str) -> Dict:
        """ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        self._debug_print(f"=" * 70)
        self._debug_print(f"ãƒ¬ãƒ¼ã‚¹ID: {race_id} ã®è§£æã‚’é–‹å§‹")
        stats = self.get_cache_stats()
        self._debug_print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥: é¦¬å{stats['name_cache_size']}ä»¶/ãƒ¬ãƒ¼ã‚¹{stats['race_cache_size']}ä»¶")
        self._debug_print(f"=" * 70)
        
        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        
        try:
            self._debug_print(f"URLã‚¢ã‚¯ã‚»ã‚¹: {url}")
            response = self.session.get(url, timeout=15)
            
            # ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚ãƒ»404ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡º
            if response.status_code == 404:
                self._debug_print(f"")
                self._debug_print(f"âš ï¸ ã€ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚æ¤œå‡ºã€‘ã“ã®ãƒ¬ãƒ¼ã‚¹ã¯å­˜åœ¨ã—ã¾ã›ã‚“", "WARNING")
                self._debug_print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: 404", "WARNING")
                self._debug_print(f"")
                return {
                    "race_name": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "distance": 0,
                    "track_type": "ä¸æ˜",
                    "course": self._get_course_name(race_id),
                    "df": pd.DataFrame(),
                    "is_cancelled": True,
                    "skip_reason": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚ï¼ˆ404ã‚¨ãƒ©ãƒ¼ï¼‰",
                    "debug_logs": self.debug_logs,
                }
            
            response.raise_for_status()
            response.encoding = 'EUC-JP'
            soup = BeautifulSoup(response.content, "html.parser", from_encoding='EUC-JP')
            self._debug_print("ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ")
            
            # ãƒšãƒ¼ã‚¸å†…å®¹ã§å–ã‚Šã‚„ã‚ãƒã‚§ãƒƒã‚¯
            page_text = soup.get_text()
            if 'å–ã‚Šã‚„ã‚' in page_text or 'ä¸­æ­¢' in page_text or 'ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“' in page_text:
                self._debug_print(f"")
                self._debug_print(f"âš ï¸ ã€ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚æ¤œå‡ºã€‘ãƒšãƒ¼ã‚¸å†…ã«å–ã‚Šã‚„ã‚è¡¨ç¤º", "WARNING")
                self._debug_print(f"")
                return {
                    "race_name": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "distance": 0,
                    "track_type": "ä¸æ˜",
                    "course": self._get_course_name(race_id),
                    "df": pd.DataFrame(),
                    "is_cancelled": True,
                    "skip_reason": "ãƒ¬ãƒ¼ã‚¹å–ã‚Šã‚„ã‚",
                    "debug_logs": self.debug_logs,
                }
                
        except Exception as e:
            raise Exception(f"ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: {e}")

        race_name = self._get_race_name(soup)
        race_distance = self._get_race_distance(soup)
        track_type = self._get_track_type(soup)
        course = self._get_course_name(race_id)

        # æ–°é¦¬æˆ¦åˆ¤å®š
        is_new_horse, reason = self.check_if_new_horse_race(soup, race_name)
        
        if is_new_horse and self.skip_new_horse:
            self._debug_print(f"")
            self._debug_print(f"ğŸš« ã€æ–°é¦¬æˆ¦æ¤œå‡ºã€‘äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã™", "WARNING")
            self._debug_print(f"   ç†ç”±: {reason}", "WARNING")
            self._debug_print(f"   ãƒ¬ãƒ¼ã‚¹å: {race_name}", "WARNING")
            self._debug_print(f"")
            
            return {
                "race_name": race_name,
                "distance": race_distance,
                "track_type": track_type,
                "course": course,
                "df": pd.DataFrame(),
                "is_new_horse_race": True,
                "skip_reason": reason,
                "debug_logs": self.debug_logs,
                "message": "æ–°é¦¬æˆ¦ã®ãŸã‚äºˆæƒ³ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ",
                "cache_stats": self.get_cache_stats()
            }

        self._debug_print(f"")
        self._debug_print(f"ã€ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã€‘")
        self._debug_print(f"  ãƒ¬ãƒ¼ã‚¹å: {race_name}")
        self._debug_print(f"  ã‚³ãƒ¼ã‚¹: {course}")
        self._debug_print(f"  è·é›¢: {race_distance}m")
        self._debug_print(f"  é¦¬å ´: {track_type}")
        self._debug_print(f"")

        horse_data = self._parse_shutuba(soup)
        
        self._debug_print(f"ã€å–å¾—ã—ãŸé¦¬ãƒ‡ãƒ¼ã‚¿ã€‘")
        for i, h in enumerate(horse_data, 1):
            self._debug_print(f"  {i}. é¦¬ç•ª{h.get('é¦¬ç•ª', '?')} {h.get('é¦¬å', 'ä¸æ˜')} | "
                            f"æ–¤é‡:{h.get('æ–¤é‡', '?')}kg | é¨æ‰‹:{h.get('é¨æ‰‹', '?')}")
        self._debug_print(f"")
        
        if not horse_data:
            raise Exception("å‡ºé¦¬è¡¨ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        # ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        horse_names = [h['é¦¬å'] for h in horse_data]
        cached_df = self._check_race_cache(race_name, horse_names)
        
        if cached_df is not None:
            self._debug_print(f"âœ… åŒä¸€ãƒ¬ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å†åˆ©ç”¨ã—ã¾ã™", "INFO")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™æ™‚ã‚‚åˆ—åã‚’ä¿è¨¼
            if 'ç·åˆæŒ‡æ•°' in cached_df.columns:
                cached_df = cached_df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
            if 'æŒ‡æ•°' not in cached_df.columns:
                cached_df['æŒ‡æ•°'] = 0.0
            
            return {
                "race_name": race_name,
                "distance": race_distance,
                "track_type": track_type,
                "course": course,
                "df": cached_df,
                "is_new_horse_race": False,
                "from_cache": True,
                "debug_logs": self.debug_logs,
                "cache_stats": self.get_cache_stats()
            }

        self._debug_print(f"ğŸ´ {len(horse_data)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
        self._debug_print(f"")

        df = pd.DataFrame(horse_data)
        df["æŒ‡æ•°"] = 0.0
        
        # ã€æ–°æ©Ÿèƒ½ã€‘å…¨é¦¬ã®è„šè³ªã‚’äº‹å‰ã«åˆ†æã—ã¦ãƒšãƒ¼ã‚¹äºˆæ¸¬
        all_running_styles = []
        self._debug_print(f"ã€è„šè³ªåˆ†æã€‘å…¨{len(df)}é ­ã®è„šè³ªã‚’åˆ¤å®šä¸­...")
        
        for index, row in df.iterrows():
            if row.get("horse_id"):
                history = self._get_horse_history_cached(
                    row["horse_id"],
                    row["é¦¬å"],
                    row["æ–¤é‡"],
                    race_distance,
                    course
                )
                running_style = self._extract_running_style_from_history(history)
                if running_style:
                    all_running_styles.append(running_style)
                    self._debug_print(f"  {row['é¦¬å']:12s}: {running_style['style']} (ä¿¡é ¼åº¦{running_style['confidence']:.2f})")
        
        # ãƒšãƒ¼ã‚¹äºˆæ¸¬
        field_size = len(df)
        pace_prediction = self._predict_race_pace(all_running_styles, field_size) if all_running_styles else None
        
        if pace_prediction:
            self._debug_print(f"")
            self._debug_print(f"ã€ãƒšãƒ¼ã‚¹äºˆæ¸¬ã€‘")
            self._debug_print(f"  äºˆæƒ³ãƒšãƒ¼ã‚¹: {pace_prediction['pace']}")
            self._debug_print(f"  å‰æ®‹ã‚Šç‡: {pace_prediction['front_ratio']:.1%}")
            self._debug_print(f"  é€ƒã’: {pace_prediction['distribution']['é€ƒã’']}é ­ / "
                            f"å…ˆè¡Œ: {pace_prediction['distribution']['å…ˆè¡Œ']}é ­ / "
                            f"å·®ã—: {pace_prediction['distribution']['å·®ã—']}é ­ / "
                            f"è¿½è¾¼: {pace_prediction['distribution']['è¿½è¾¼']}é ­")
            self._debug_print(f"  ç›´ç·šé•·: {pace_prediction.get('straight_length', 400)}m")
        
        self._debug_print(f"")

        for index, row in df.iterrows():
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—
            if self.progress_callback:
                self.progress_callback(row['é¦¬å'], index + 1, len(df))
            
            if row.get("horse_id"):
                self._debug_print(f"-" * 60)
                self._debug_print(f"ã€{row['é¦¬å']}ã€‘(é¦¬ç•ª:{row['é¦¬ç•ª']}) åˆ†æé–‹å§‹")
                self._debug_print(f"  æ–¤é‡: {row['æ–¤é‡']}kg | é¨æ‰‹: {row['é¨æ‰‹']}")
                
                history = self._get_horse_history_cached(
                    row["horse_id"],
                    row["é¦¬å"],
                    row["æ–¤é‡"],
                    race_distance,
                    course
                )
                
                if history:
                    self._debug_print(f"  éå»æˆ¦ç¸¾: {len(history)}ãƒ¬ãƒ¼ã‚¹å–å¾—")
                    for idx, race in enumerate(history[:5], 1):
                        last_3f = race.get('last_3f', 0)
                        race_avg = race.get('race_avg_last_3f', 0)
                        
                        dist = race.get('dist', 1600)
                        if race_avg <= 0:
                            if dist <= 1400:
                                race_avg = 34.5
                            elif dist <= 1800:
                                race_avg = 35.0
                            elif dist <= 2200:
                                race_avg = 36.0
                            else:
                                race_avg = 37.0
                        
                        is_fast = last_3f > 0 and last_3f < race_avg
                        fast_mark = "â—¯" if is_fast else " "
                        
                        weight = race.get('weight', 0)
                        weight_mark = "â˜…" if weight >= 57.0 else " " if weight >= 55.0 else ""
                        
                        self._debug_print(f"    {idx}èµ°å‰: {race.get('race_name', 'ä¸æ˜')[:15]:15s} | "
                                        f"{race.get('dist', '?')}m | "
                                        f"ç€é †:{race.get('chakujun', '?'):>2}ç€ | "
                                        f"æ–¤é‡:{weight:>4.1f}kg{weight_mark} | "
                                        f"ä¸ŠãŒã‚Š3F:{last_3f:>5.1f}s ({fast_mark}åŸºæº–{race_avg:.1f}s)")
                else:
                    self._debug_print(f"  âš ï¸ éå»æˆ¦ç¸¾ãªã—ï¼ˆæ–°é¦¬ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                
                if history:
                    # ã€æ–°æ©Ÿèƒ½ã€‘ã“ã®é¦¬ã®è„šè³ªã‚’å–å¾—
                    running_style_info = self._extract_running_style_from_history(history)
                    
                    analysis = self.scorer.calculate_total_score(
                        current_weight=row["æ–¤é‡"],
                        target_course=course,
                        target_distance=race_distance,
                        history_data=history,
                        target_track_type=track_type,
                        running_style_info=running_style_info,
                        race_pace_prediction=pace_prediction
                    )
                    
                    df.at[index, "æŒ‡æ•°"] = analysis["total_score"]
                    
                    # ã€æ–°æ©Ÿèƒ½ã€‘format_score_breakdownã‚’ä½¿ç”¨
                    breakdown_text = self.scorer.format_score_breakdown(analysis, race_distance)
                    for line in breakdown_text.split('\n'):
                        self._debug_print(f"  {line}")
                else:
                    df.at[index, "æŒ‡æ•°"] = 0.0
                    self._debug_print(f"  âš ï¸ éå»æˆ¦ç¸¾ãªã—ã®ãŸã‚0ç‚¹")
                
                time.sleep(self.scraping_delay)

        df = df.sort_values("æŒ‡æ•°", ascending=False).reset_index(drop=True)
        
        # æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        self._debug_print(f"")
        self._debug_print(f"=" * 70)
        self._debug_print(f"ã€æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘")
        stats = self.get_cache_stats()
        self._debug_print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: é¦¬å{stats['name_cache_size']}ä»¶/ãƒ¬ãƒ¼ã‚¹{stats['race_cache_size']}ä»¶/ãƒ’ãƒƒãƒˆç‡{stats['hit_rate']:.1f}%")
        self._debug_print(f"=" * 70)
        
        marks = []
        for i, row in df.iterrows():
            is_dangerous = row["æŒ‡æ•°"] <= 0
            
            if is_dangerous:
                mark = "Ã—" if i <= 5 else ""
            elif i == 0:
                mark = "â—"
            elif i == 1:
                mark = "â—‹"
            elif i == 2:
                mark = "â–²"
            elif i <= 5:
                mark = "â–³"
            else:
                mark = ""
            
            marks.append(mark)
            
            danger_mark = "âš ï¸" if is_dangerous else "  "
            self._debug_print(f"  {i+1:2d}ä½ {danger_mark} {mark:4s} é¦¬ç•ª{row['é¦¬ç•ª']:>2s} {row['é¦¬å']:12s} "
                            f"æŒ‡æ•°:{row['æŒ‡æ•°']:6.1f} æ–¤é‡:{row['æ–¤é‡']:4.1f}kg")
        self._debug_print(f"=" * 70)
        
        df["å°"] = marks

        # ãƒ¬ãƒ¼ã‚¹çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._save_race_cache(race_name, df)

        # ============================================================
        # ã€é‡è¦ã€‘åˆ—åã‚’ç¢ºå®Ÿã«'æŒ‡æ•°'ã«çµ±ä¸€ï¼ˆé˜²å¾¡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼‰
        # ============================================================
        if 'ç·åˆæŒ‡æ•°' in df.columns:
            df = df.rename(columns={'ç·åˆæŒ‡æ•°': 'æŒ‡æ•°'})
        
        if 'æŒ‡æ•°' not in df.columns:
            df['æŒ‡æ•°'] = 0.0
        # ============================================================

        return {
            "race_name": race_name,
            "distance": race_distance,
            "track_type": track_type,
            "course": course,
            "df": df,
            "is_new_horse_race": False,
            "from_cache": False,
            "debug_logs": self.debug_logs,
            "cache_stats": self.get_cache_stats()
        }

    def _get_horse_history_cached(self, horse_id: str, horse_name: str,
                                  current_weight: float,
                                  race_distance: int, course: str) -> List[Dict]:
        """é¦¬åãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé¦¬ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        cached_data = self._get_from_cache(horse_name)
        if cached_data is not None:
            return cached_data
        
        self.api_calls += 1
        self._debug_print(f"  ğŸŒ APIå‘¼ã³å‡ºã— (é¦¬å: {horse_name})", "DEBUG")
        history = self._get_horse_history(horse_id, current_weight, race_distance, course)
        
        if history:
            self._save_to_cache(horse_name, history)
        
        return history

    def _get_horse_history(self, horse_id: str, current_weight: float,
                          target_distance: int, target_course: str) -> List[Dict]:
        """å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
        
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")
            
            table = soup.find("table", class_="db_h_race_results")
            if not table:
                return []
            
            headers = [th.text.strip() for th in table.find_all("th")]
            
            def find_col(keywords):
                for kw in keywords:
                    for i, h in enumerate(headers):
                        if kw in h:
                            return i
                return -1
            
            idx_date = find_col(["æ—¥ä»˜"])
            idx_course = find_col(["é–‹å‚¬"])
            idx_race = find_col(["ãƒ¬ãƒ¼ã‚¹å"])
            idx_dist = find_col(["è·é›¢"])
            idx_chakujun = find_col(["ç€é †"])
            idx_weight = find_col(["æ–¤é‡"])
            idx_chakusa = find_col(["ç€å·®"])
            idx_3f = find_col(["ä¸Šã‚Š"])
            idx_corner = find_col(["é€šé", "ãƒšãƒ¼ã‚¹"])  # é€šéé †ä½ï¼ˆ4è§’ãªã©ï¼‰
            idx_tosu = find_col(["é ­æ•°", "é¦¬"])  # é ­æ•°
            
            if idx_date == -1: idx_date = 0
            if idx_course == -1: idx_course = 1
            if idx_race == -1: idx_race = 4
            if idx_dist == -1: idx_dist = 14
            if idx_chakujun == -1: idx_chakujun = 11
            if idx_weight == -1: idx_weight = 13
            if idx_chakusa == -1: idx_chakusa = 18
            if idx_3f == -1: idx_3f = 20
            # é€šéé †ä½ã¨é ­æ•°ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè¦‹ã¤ã‹ã‚‰ãªãã¦ã‚‚-1ã®ã¾ã¾ï¼‰
            
            rows = table.find_all("tr")[1:6]
            history = []
            
            for idx, row in enumerate(rows):
                cols = row.find_all("td")
                if len(cols) < max(idx_date, idx_course, idx_race, idx_dist, 
                                  idx_chakujun, idx_weight, idx_chakusa) + 1:
                    continue
                
                try:
                    date = cols[idx_date].text.strip().replace("/", ".")
                    course_name = cols[idx_course].text.strip()
                    
                    race_cell = cols[idx_race]
                    race_link = race_cell.find("a")
                    race_name = race_link.get_text(strip=True) if race_link else race_cell.get_text(strip=True)
                    
                    race_id = ""
                    if race_link:
                        href = race_link.get("href", "")
                        match = re.search(r"race/(\d{12})", href)
                        if match:
                            race_id = match.group(1)
                    
                    dist_text = cols[idx_dist].text.strip()
                    
                    # ãƒˆãƒ©ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‚’è·é›¢åˆ—ã‹ã‚‰ç›´æ¥ãƒ‘ãƒ¼ã‚¹ï¼ˆä¾‹: "èŠ1600", "ãƒ€1200", "éšœ3000"ï¼‰
                    track_type_match = re.match(r"^(èŠ|ãƒ€|ãƒ€ãƒ¼ãƒˆ|éšœ)", dist_text)
                    if track_type_match:
                        track_prefix = track_type_match.group(1)
                        if track_prefix == "èŠ":
                            race_track_type = "èŠ"
                        elif track_prefix in ["ãƒ€", "ãƒ€ãƒ¼ãƒˆ"]:
                            race_track_type = "ãƒ€ãƒ¼ãƒˆ"
                        elif track_prefix == "éšœ":
                            race_track_type = "éšœå®³"
                        else:
                            race_track_type = "ä¸æ˜"
                    else:
                        race_track_type = "ä¸æ˜"
                    
                    dist_match = re.search(r"(\d+)", dist_text)
                    distance = int(dist_match.group(1)) if dist_match else 0
                    
                    chakujun_text = cols[idx_chakujun].text.strip()
                    chakujun_match = re.search(r"(\d+)", chakujun_text)
                    chakujun = int(chakujun_match.group(1)) if chakujun_match else 99
                    
                    chakusa_text = cols[idx_chakusa].text.strip()
                    if not chakusa_text or chakusa_text in ["-", "**", "---"]:
                        chakusa_text = "0.0" if chakujun == 1 else "1.0"
                    
                    weight_text = cols[idx_weight].text.strip()
                    try:
                        weight = float(weight_text)
                    except:
                        weight = current_weight
                    
                    time_3f_text = cols[idx_3f].text.strip() if idx_3f < len(cols) else ""
                    try:
                        last_3f = float(time_3f_text)
                    except:
                        last_3f = 0.0
                    
                    # é€šéé †ä½ã‚’å–å¾—ï¼ˆ4è§’é †ä½ãªã©ï¼‰
                    corner_pos = 0
                    if idx_corner != -1 and idx_corner < len(cols):
                        corner_text = cols[idx_corner].text.strip()
                        # "1-1-1-1"ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰æœ€å¾Œã®æ•°å­—ï¼ˆ4è§’ï¼‰ã‚’å–å¾—
                        positions = re.findall(r'\d+', corner_text)
                        if positions:
                            corner_pos = int(positions[-1])  # æœ€å¾Œã®ä½ç½®ï¼ˆ4è§’ï¼‰
                    
                    # é ­æ•°ã‚’å–å¾—
                    field_size = 16  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                    if idx_tosu != -1 and idx_tosu < len(cols):
                        tosu_text = cols[idx_tosu].text.strip()
                        tosu_match = re.search(r'(\d+)', tosu_text)
                        if tosu_match:
                            field_size = int(tosu_match.group(1))
                    
                    race_stats = {}
                    if race_id and last_3f > 0:
                        time.sleep(0.3)
                        race_stats = self._get_race_last_3f_stats(race_id)
                    
                    history.append({
                        'date': date,
                        'course': course_name,
                        'dist': distance,
                        'track_type': race_track_type,  # è¿½åŠ : ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã—ãŸãƒˆãƒ©ãƒƒã‚¯ã‚¿ã‚¤ãƒ—
                        'chakujun': chakujun,
                        'chakusa': chakusa_text,
                        'weight': weight,
                        'last_3f': last_3f,
                        'race_name': race_name,
                        'race_avg_last_3f': race_stats.get('avg_last_3f', 0.0),
                        'race_min_last_3f': race_stats.get('min_last_3f', 0.0),
                        'race_max_last_3f': race_stats.get('max_last_3f', 0.0),
                        'race_std_last_3f': race_stats.get('std_last_3f', 0.0),
                        'all_horses_results': race_stats.get('all_horses_results', []),  # è¿½åŠ 
                        'corner_pos': corner_pos,  # è¿½åŠ : é€šéé †ä½ï¼ˆ4è§’ï¼‰
                        'field_size': field_size,  # è¿½åŠ : é ­æ•°
                    })
                    
                except Exception as e:
                    continue
            
            return history
            
        except Exception as e:
            logger.error(f"æˆ¦ç¸¾å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _get_course_name(self, race_id: str) -> str:
        venues = {
            "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ",
            "05": "æ±äº¬", "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½",
            "09": "é˜ªç¥", "10": "å°å€‰"
        }
        code = race_id[4:6] if len(race_id) >= 6 else ""
        return venues.get(code, "ä¸æ˜")

    # ================================================================
    # ã€é–‹å‚¬æ—¥ã‹ã‚‰race_idãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹æ©Ÿèƒ½ã€‘
    # ================================================================

    VENUE_CODES = {
        "æœ­å¹Œ": "01", "å‡½é¤¨": "02", "ç¦å³¶": "03", "æ–°æ½Ÿ": "04",
        "æ±äº¬": "05", "ä¸­å±±": "06", "ä¸­äº¬": "07", "äº¬éƒ½": "08",
        "é˜ªç¥": "09", "å°å€‰": "10"
    }

    def get_kaisai_list(self, kaisai_date: str) -> List[Dict]:
        """
        é–‹å‚¬æ—¥ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹
        
        Args:
            kaisai_date: é–‹å‚¬æ—¥ (ä¾‹: "20260221")
        
        Returns:
            [{'race_id': '...', 'course': 'æ±äº¬', 'race_num': 1, 'race_name': '...'}, ...]
        """
        url = f"https://race.netkeiba.com/top/race_list_sub.html?kaisai_date={kaisai_date}"
        
        try:
            self._debug_print(f"é–‹å‚¬æ—¥ {kaisai_date} ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ä¸­...")
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = 'EUC-JP'
            soup = BeautifulSoup(response.content, "html.parser", from_encoding='EUC-JP')
            
            races = []
            
            # ãƒ¬ãƒ¼ã‚¹ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢ï¼ˆrace_idã‚’å«ã‚€aã‚¿ã‚°ï¼‰
            for a_tag in soup.find_all("a", href=re.compile(r"race_id=(\d{12})")):
                href = a_tag.get("href", "")
                match = re.search(r"race_id=(\d{12})", href)
                if match:
                    race_id = match.group(1)
                    course = self._get_course_name(race_id)
                    race_num = int(race_id[10:12]) if len(race_id) >= 12 else 0
                    race_name = a_tag.get_text(strip=True)
                    
                    # é‡è¤‡é™¤å»
                    if not any(r['race_id'] == race_id for r in races):
                        races.append({
                            'race_id': race_id,
                            'course': course,
                            'race_num': race_num,
                            'race_name': race_name if race_name else f"{course}{race_num}R",
                            'kaisai_date': kaisai_date,
                        })
            
            # åˆ¥ã®å–å¾—æ–¹æ³•ã‚‚è©¦ã¿ã‚‹ï¼ˆãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼‰
            if not races:
                url2 = f"https://race.netkeiba.com/top/?kaisai_date={kaisai_date}"
                response2 = self.session.get(url2, timeout=15)
                response2.raise_for_status()
                response2.encoding = 'EUC-JP'
                soup2 = BeautifulSoup(response2.content, "html.parser", from_encoding='EUC-JP')
                
                for a_tag in soup2.find_all("a", href=re.compile(r"race_id=(\d{12})")):
                    href = a_tag.get("href", "")
                    match = re.search(r"race_id=(\d{12})", href)
                    if match:
                        race_id = match.group(1)
                        course = self._get_course_name(race_id)
                        race_num = int(race_id[10:12]) if len(race_id) >= 12 else 0
                        race_name = a_tag.get_text(strip=True)
                        
                        if not any(r['race_id'] == race_id for r in races):
                            races.append({
                                'race_id': race_id,
                                'course': course,
                                'race_num': race_num,
                                'race_name': race_name if race_name else f"{course}{race_num}R",
                                'kaisai_date': kaisai_date,
                            })
            
            # ä¸¦ã³æ›¿ãˆï¼šç«¶é¦¬å ´â†’ãƒ¬ãƒ¼ã‚¹ç•ªå·é †
            races.sort(key=lambda x: (x['course'], x['race_num']))
            
            self._debug_print(f"  â†’ {len(races)}ãƒ¬ãƒ¼ã‚¹å–å¾—å®Œäº†")
            return races
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒ¼ã‚¹ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼ ({kaisai_date}): {e}")
            return []

    def get_kaisai_list_multi(self, dates: List[str]) -> Dict[str, List[Dict]]:
        """
        è¤‡æ•°ã®é–‹å‚¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹
        
        Args:
            dates: é–‹å‚¬æ—¥ãƒªã‚¹ãƒˆ (ä¾‹: ["20260221", "20260222"])
        
        Returns:
            {'20260221': [...], '20260222': [...]}
        """
        result = {}
        for date in dates:
            result[date] = self.get_kaisai_list(date)
            time.sleep(self.scraping_delay)
        return result

    def format_kaisai_date(self, date_str: str) -> str:
        """
        é–‹å‚¬æ—¥ã‚’è¦‹ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        
        Args:
            date_str: "20260221"
        
        Returns:
            "2026å¹´2æœˆ21æ—¥(åœŸ)"
        """
        try:
            dt = datetime.strptime(date_str, "%Y%m%d")
            weekdays = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
            wd = weekdays[dt.weekday()]
            return dt.strftime(f"%Yå¹´%-mæœˆ%-dæ—¥({wd})")
        except Exception:
            return date_str

    def _parse_shutuba(self, soup: BeautifulSoup) -> List[Dict]:
        horse_data = []
        
        table = None
        patterns = [
            ("table", {"class_": "Shutuba_Table"}),
            ("table", {"class_": re.compile(r"shutuba", re.I)}),
            ("table", {"class_": "RaceList"}),
            ("table", {"class_": re.compile(r"race.*list", re.I)}),
        ]
        
        for tag, attrs in patterns:
            table = soup.find(tag, attrs)
            if table:
                break
        
        if not table:
            for t in soup.find_all("table"):
                if t.find("th") and ("é¦¬å" in str(t) or "horse" in str(t).lower()):
                    table = t
                    break
        
        if not table:
            self._debug_print("âŒ å‡ºé¦¬è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return []

        rows = table.find_all("tr")
        start = 1 if rows and rows[0].find("th") else 0
        
        for row_idx, row in enumerate(rows[start:], 1):
            cols = row.find_all(["td", "th"])
            if len(cols) < 5:
                continue
            
            try:
                info = self._extract_horse_info(cols, row, row_idx)
                if info and info.get("é¦¬å") and info.get("horse_id"):
                    horse_data.append(info)
            except Exception as e:
                if self.debug_mode:
                    self._debug_print(f"  è¡Œ{row_idx}ã®è§£æå¤±æ•—: {e}", "WARNING")
                continue
        
        return horse_data

    def _extract_horse_info(self, cols, row, row_idx: int) -> Optional[Dict]:
        info = {
            "æ ": "", "é¦¬ç•ª": "", "é¦¬å": "", "æ€§é½¢": "",
            "æ–¤é‡": 54.0, "é¨æ‰‹": "", "ã‚ªãƒƒã‚º": 1.0, "horse_id": ""
        }
        
        for col in cols:
            if not info["é¦¬å"]:
                link = col.find("a", href=re.compile(r"/horse/\d+"))
                if link:
                    info["é¦¬å"] = link.get_text(strip=True)
                    href = link.get("href", "")
                    match = re.search(r"/horse/(\d{10,})", href)
                    if match:
                        info["horse_id"] = match.group(1)
        
        for col in cols:
            if not info["é¨æ‰‹"]:
                jockey_link = col.find("a", href=re.compile(r"/jockey/"))
                if jockey_link:
                    info["é¨æ‰‹"] = jockey_link.get_text(strip=True)
        
        for idx in range(min(3, len(cols))):
            col = cols[idx]
            text = col.get_text(strip=True)
            
            if not info["æ "] and len(text) == 1 and text.isdigit() and 1 <= int(text) <= 8:
                info["æ "] = text
            elif not info["é¦¬ç•ª"] and len(text) <= 2 and text.isdigit() and 1 <= int(text) <= 18:
                info["é¦¬ç•ª"] = text
        
        for col in cols:
            text = col.get_text(strip=True)
            
            if not info["æ€§é½¢"]:
                if re.match(r"^[ç‰¡ç‰ã‚»]\d{1,2}$", text):
                    info["æ€§é½¢"] = text
            
            if info["æ–¤é‡"] == 54.0:
                weight_match = re.match(r"^(\d{2}\.\d)$", text)
                if weight_match:
                    val = float(weight_match.group(1))
                    if 48.0 <= val <= 60.0:
                        info["æ–¤é‡"] = val
                        continue
                
                weight_match = re.match(r"^(\d{2})$", text)
                if weight_match:
                    val = float(weight_match.group(1))
                    if 48.0 <= val <= 60.0:
                        info["æ–¤é‡"] = val
                        continue
        
        if not info["é¦¬å"] or not info["horse_id"]:
            return None
        
        if not info["æ "]:
            info["æ "] = str(row_idx)
        if not info["é¦¬ç•ª"]:
            info["é¦¬ç•ª"] = str(row_idx)
        
        return info

    def _get_race_last_3f_stats(self, race_id: str) -> Dict:
        """éå»ãƒ¬ãƒ¼ã‚¹ã®ä¸ŠãŒã‚Š3Fçµ±è¨ˆã¨å‡ºèµ°é¦¬å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        url = f"https://db.netkeiba.com/race/{race_id}/"
        
        try:
            response = self.session.get(url, timeout=15)
            
            if response.status_code == 404:
                return {}
            
            response.raise_for_status()
            response.encoding = 'EUC-JP'
            soup = BeautifulSoup(response.content, "html.parser", from_encoding='EUC-JP')
            
            table = soup.find("table", class_="race_table_01")
            if not table:
                return {}
            
            headers = table.find_all("th")
            
            # å„åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            last_3f_idx = -1
            chakujun_idx = -1
            time_diff_idx = -1
            
            for i, th in enumerate(headers):
                text = th.get_text(strip=True)
                if any(kw in text for kw in ["ä¸Šã‚Š", "ä¸ŠãŒã‚Š", "3F"]):
                    last_3f_idx = i
                elif "ç€é †" in text or text == "ç€":
                    chakujun_idx = i
                elif "ã‚¿ã‚¤ãƒ å·®" in text or "ç€å·®" in text:
                    time_diff_idx = i
            
            if last_3f_idx == -1:
                last_3f_idx = len(headers) - 2
            if chakujun_idx == -1:
                chakujun_idx = 0
            if time_diff_idx == -1:
                time_diff_idx = 7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½ç½®
            
            values = []
            all_horses_results = []  # å…¨é¦¬ã®ãƒ‡ãƒ¼ã‚¿
            
            for row in table.find_all("tr")[1:]:
                tds = row.find_all("td")
                if len(tds) > max(last_3f_idx, chakujun_idx, time_diff_idx):
                    try:
                        # ä¸ŠãŒã‚Š3Fã‚’å–å¾—
                        last_3f_text = tds[last_3f_idx].get_text(strip=True)
                        last_3f_text = re.sub(r"[()ï¼ˆï¼‰]", "", last_3f_text)
                        
                        if last_3f_text and last_3f_text != '-':
                            last_3f = float(last_3f_text)
                            
                            if 30 < last_3f < 50:
                                values.append(last_3f)
                                
                                # ç€é †ã‚’å–å¾—
                                chakujun_text = tds[chakujun_idx].get_text(strip=True)
                                chakujun_match = re.search(r'(\d+)', chakujun_text)
                                chakujun = int(chakujun_match.group(1)) if chakujun_match else 99
                                
                                # ã‚¿ã‚¤ãƒ å·®ã‚’å–å¾—
                                time_diff_text = tds[time_diff_idx].get_text(strip=True)
                                goal_time_diff = 0.0
                                
                                if chakujun == 1:
                                    goal_time_diff = 0.0
                                elif time_diff_text and time_diff_text not in ['-', '']:
                                    # "1.5"ã‚„"1/2"ãªã©ã®å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                                    if '/' in time_diff_text:
                                        # "1/2" â†’ 0.05ç§’
                                        parts = time_diff_text.split('/')
                                        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():
                                            goal_time_diff = int(parts[0]) * 0.1 / int(parts[1])
                                    else:
                                        try:
                                            goal_time_diff = float(time_diff_text)
                                        except:
                                            goal_time_diff = 1.0
                                else:
                                    goal_time_diff = 1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                                
                                all_horses_results.append({
                                    'chakujun': chakujun,
                                    'last_3f': last_3f,
                                    'goal_time_diff': goal_time_diff
                                })
                    except:
                        continue
            
            if not values:
                return {}
            
            result = {
                'avg_last_3f': round(statistics.mean(values), 2),
                'min_last_3f': round(min(values), 2),
                'max_last_3f': round(max(values), 2),
                'median_last_3f': round(statistics.median(values), 2),
                'std_last_3f': round(statistics.stdev(values), 2) if len(values) > 1 else 0.0,
                'count': len(values),
                'all_horses_results': all_horses_results  # è¿½åŠ : å…¨é¦¬ã®ãƒ‡ãƒ¼ã‚¿
            }
            
            return result
            
        except Exception as e:
            return {}

    def _get_race_name(self, soup: BeautifulSoup) -> str:
        elem = soup.find("div", class_="RaceName")
        if elem:
            name = elem.get_text(strip=True)
            name = re.sub(r"å‡ºé¦¬è¡¨.*", "", name).strip()
            if name:
                return name
        
        for h1 in soup.find_all("h1"):
            name = h1.get_text(strip=True)
            if name and len(name) > 2:
                return re.sub(r"å‡ºé¦¬è¡¨.*", "", name).strip()
        
        return "ãƒ¬ãƒ¼ã‚¹"

    def _get_race_distance(self, soup: BeautifulSoup) -> int:
        elem = soup.find("div", class_="RaceData01")
        if elem:
            match = re.search(r"[èŠãƒ€éšœ](\d+)m", elem.text)
            if match:
                return int(match.group(1))
        return 1600

    def _get_track_type(self, soup: BeautifulSoup) -> str:
        elem = soup.find("div", class_="RaceData01")
        if elem:
            text = elem.text
            if "èŠ" in text:
                return "èŠ"
            elif "ãƒ€" in text or "ãƒ€ãƒ¼ãƒˆ" in text:
                return "ãƒ€ãƒ¼ãƒˆ"
            elif "éšœ" in text:
                return "éšœå®³"
        return "ä¸æ˜"


if __name__ == "__main__":
    print("âœ… NetkeibaRaceScraper v4.2ï¼ˆå®Œå…¨ç‰ˆãƒ»åˆ—å'æŒ‡æ•°'çµ±ä¸€ï¼‰loaded")


# ================================================================
# Streamlit UI ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆã‚¯ãƒ©ã‚¹å¤–ï¼‰
# ================================================================

def render_kaisai_selector(scraper) -> "Optional[str]":
    """
    Streamlitç”¨ï¼šé–‹å‚¬æ—¥ãƒ»ç«¶é¦¬å ´ãƒ»ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’é¸æŠã—ã¦race_idã‚’è¿”ã™UI

    ä½¿ç”¨ä¾‹ï¼ˆapp.pyç­‰ï¼‰:
        from scraper_v3_fixed import NetkeibaRaceScraper, render_kaisai_selector
        scraper = NetkeibaRaceScraper()
        race_id = render_kaisai_selector(scraper)
        if race_id:
            result = scraper.get_race_data(race_id)

    Returns:
        é¸æŠã•ã‚ŒãŸrace_id (str) or None
    """
    try:
        import streamlit as st
    except ImportError:
        raise ImportError("streamlit ãŒå¿…è¦ã§ã™: pip install streamlit")

    st.subheader("ğŸ‡ é–‹å‚¬æ—¥ãƒ»ãƒ¬ãƒ¼ã‚¹é¸æŠ")

    # ========== é–‹å‚¬æ—¥é¸æŠ ==========
    col1, col2 = st.columns([2, 1])

    with col1:
        from datetime import date as date_type
        selected_date = st.date_input(
            "é–‹å‚¬æ—¥ã‚’é¸æŠ",
            value=date_type.today(),
            help="ãƒ¬ãƒ¼ã‚¹ãŒé–‹å‚¬ã•ã‚Œã‚‹æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

    with col2:
        fetch_clicked = st.button("ğŸ” ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—", use_container_width=True)

    if fetch_clicked:
        date_str = selected_date.strftime("%Y%m%d")
        with st.spinner(f"{scraper.format_kaisai_date(date_str)} ã®ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—ä¸­..."):
            races = scraper.get_kaisai_list(date_str)

        if races:
            st.session_state["kaisai_races"] = races
            st.session_state["kaisai_date_str"] = date_str
            st.success(f"âœ… {len(races)}ãƒ¬ãƒ¼ã‚¹å–å¾—ã—ã¾ã—ãŸ")
        else:
            st.warning("âš ï¸ ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆé–‹å‚¬æ—¥ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
            st.session_state["kaisai_races"] = []

    # ========== ãƒ¬ãƒ¼ã‚¹é¸æŠ ==========
    races = st.session_state.get("kaisai_races", [])

    if not races:
        st.info("ğŸ‘† é–‹å‚¬æ—¥ã‚’é¸æŠã—ã¦ã€Œãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        return None

    # ç«¶é¦¬å ´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    venues_in_races = sorted(set(r["course"] for r in races))

    col3, col4 = st.columns(2)

    with col3:
        selected_venue = st.selectbox(
            "ç«¶é¦¬å ´",
            options=["ã™ã¹ã¦"] + venues_in_races,
            help="ç«¶é¦¬å ´ã‚’çµã‚Šè¾¼ã‚ã¾ã™"
        )

    filtered_races = [
        r for r in races
        if selected_venue == "ã™ã¹ã¦" or r["course"] == selected_venue
    ]

    if not filtered_races:
        st.warning("è©²å½“ã™ã‚‹ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
        return None

    with col4:
        race_options = {
            f"{r['course']} {r['race_num']}Rã€€{r['race_name']}": r['race_id']
            for r in filtered_races
        }
        selected_label = st.selectbox(
            "ãƒ¬ãƒ¼ã‚¹ç•ªå·",
            options=list(race_options.keys()),
        )

    if selected_label:
        race_id = race_options[selected_label]
        st.code(f"race_id: {race_id}", language=None)
        return race_id

    return None
